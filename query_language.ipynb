{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vosA89WEixQc"
   },
   "source": [
    "# pandas temporal query language\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l9smRfNEU7kL"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import ast\n",
    "import glob\n",
    "import ntpath\n",
    "import os\n",
    "\n",
    "from itertools import zip_longest, chain\n",
    "\n",
    "from itertools import product\n",
    "from functools import lru_cache\n",
    "from functools import singledispatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LJgdBxlWEy-r"
   },
   "source": [
    "# General helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qG9pbooAEst9"
   },
   "source": [
    "## Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SVQwSQ67O_8x"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class Info():\n",
    "  \"\"\"\n",
    "  A class to store information about the data and results from analysis\n",
    "  \"\"\"\n",
    "  def __init__(self):\n",
    "      self.evaluated = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P4-2Ic_OF3Gl"
   },
   "source": [
    "## memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rpi14aJEFxot"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def memory(info, func, expr):\n",
    "  \"\"\"\n",
    "  checks if the function has been called with the same argument previously and\n",
    "  if so, returns the same results instead of running the function again\n",
    "\n",
    "  args:\n",
    "    - \n",
    "  \"\"\"\n",
    "  rows=None\n",
    "  if info:\n",
    "    if func in info.evaluated:\n",
    "      if expr in info.evaluated[func]:\n",
    "        rows = info.evaluated[func][expr]\n",
    "    else:\n",
    "      info.evaluated[func] = {}\n",
    "  else:\n",
    "    info = Info()\n",
    "    info.evaluated[func] = {}\n",
    "  return info, rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K9tHjHXQEoAo"
   },
   "source": [
    "## listify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VBF5ZPs2EoAw"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def listify(string_or_list):\n",
    "    \"\"\"\n",
    "    return a list if the input is a string, if not: returns the input as it was\n",
    "\n",
    "    Args:\n",
    "        string_or_list (str or any):\n",
    "\n",
    "    Returns:\n",
    "        A list if the input is a string, if not: returns the input as it was\n",
    "\n",
    "    Note:\n",
    "        - allows user to use a string as an argument instead of single lists\n",
    "        - cols='icd10' is allowed instead of cols=['icd10']\n",
    "        - cols='icd10' is transformed to cols=['icd10'] by this function\n",
    "\n",
    "    \"\"\"\n",
    "    if isinstance(string_or_list, str):\n",
    "        string_or_list = [string_or_list]\n",
    "    return string_or_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YQhtgvn7EUSN"
   },
   "source": [
    "## unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WCH02_MBEY_s"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# A function to identify all unique values in one or more columns \n",
    "# with one or multiple codes in each cell\n",
    "\n",
    "def unique(df, cols=None, sep=None, all_str=True):\n",
    "  \"\"\"\n",
    "  Lists unique values from one or more columns\n",
    "  \n",
    "  sep (str): separator if cells have multiple values\n",
    "  all_str (bool): converts all values to strings\n",
    "  \n",
    "  unique(df=df, cols='inpatient', sep=',')\n",
    "  \"\"\"\n",
    "  # if no column(s) are specified, find unique values in whole dataframe\n",
    "  if cols==None:\n",
    "    cols=list(df.columns)\n",
    "  cols = listify(cols)\n",
    "\n",
    "  # multiple values with separator in cells\n",
    "  if sep:\n",
    "    all_unique=set()\n",
    "\n",
    "    for col in cols:\n",
    "      new_unique = set(df[col].str.cat(sep=',').split(','))\n",
    "      all_unique.update(new_unique)\n",
    "  # single valued cells\n",
    "  else:\n",
    "    all_unique = pd.unique(df[cols].values.ravel('K'))\n",
    "  \n",
    "  # if need to make sure all elements are strings without surrounding spaces\n",
    "  if all_str:\n",
    "    all_unique=[str(value).strip() for value in all_unique]\n",
    "\n",
    "  return all_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z69nIn-KK4az"
   },
   "outputs": [],
   "source": [
    "#unique(df=df, cols='codes', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "goKBivTUFNoU"
   },
   "source": [
    "## del dot and zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nk49gESsFNoY"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def del_dot(code):\n",
    "  if isinstance(code, str):\n",
    "    return code.replace('.','')\n",
    "  else:\n",
    "    codes = [c.replace('.','') for c in code]\n",
    "  return codes\n",
    "\n",
    "def del_zero(code, left=True, right=False):\n",
    "  if isinstance(codes, str):\n",
    "    codes=[code]\n",
    "  if left:\n",
    "    codes = [c.lstrip('0') for c in code]\n",
    "  if right:\n",
    "    codes = [c.rstrip('0') for c in code]\n",
    "  if isinstance(code, str):\n",
    "    codes=codes[0]\n",
    "  return codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hxm-5QiEFe60"
   },
   "source": [
    "# Notations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bEOTYsewSkaS"
   },
   "source": [
    "## expand hyphen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2OwcbGI7Br2X"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# function to expand a string like 'K51.2-K53.8' to a list of codes \n",
    "\n",
    "# Need regex to extract the number component of the input string\n",
    "\n",
    "# The singledispach decorator enables us to have the same name, but use \n",
    "# different functions depending on the datatype of the first argument.\n",
    "#\n",
    "# In our case we want one function to deal with a single string input, and\n",
    "# another to handle a list of strings. It could all be handled in a single \n",
    "# function using nested if, but singledispatch makes it less messy and more fun!\n",
    "\n",
    "\n",
    "# Here is the main function, it is just the name and an error message if the \n",
    "# argument does not fit any of the inputs that wil be allowed\n",
    "\n",
    "@singledispatch\n",
    "def expand_hyphen(expr):\n",
    "  \"\"\"\n",
    "  Expands codes expression(s) that have hyphens to list of all codes\n",
    "\n",
    "  Args:\n",
    "      code (str or list of str): String or list of strings to be expanded \n",
    "  \n",
    "  Returns:\n",
    "      List of strings\n",
    "  \n",
    "  Examples:\n",
    "      expand_hyphen('C00*-C26*')\n",
    "      expand_hyphen('b01.1*-b09.9*')\n",
    "      expand_hyphen('n02.2-n02.7')\n",
    "      expand_hyphen('c00*-c260')\n",
    "      expand_hyphen('b01-b09')\n",
    "      expand_hyphen('b001.1*-b009.9*')\n",
    "      expand_hyphen(['b001.1*-b009.9*', 'c11-c15'])\n",
    "  Note:\n",
    "      Unequal number of decimals in start and end code is problematic.\n",
    "      Example: C26.0-C27.11 will not work since the meaning is not obvious:\n",
    "      Is the step size 0.01? In which case C27.1 will not be included, while \n",
    "      C27.10 will be (and traing zeros can be important in codes)\n",
    "  \"\"\"\n",
    "  raise ValueError('The argument must be a string or a list')\n",
    "\n",
    "# register the function to be used if the input is a string\n",
    "@expand_hyphen.register(str)\n",
    "def _(expr):\n",
    "    # return immediately if nothing to expand\n",
    "    if '-' not in expr:\n",
    "      return [expr]\n",
    "\n",
    "    lower, upper = expr.split('-')\n",
    "    \n",
    "    lower=lower.strip()\n",
    "\n",
    "    # identify the numeric component of the code\n",
    "    lower_str = re.search(\"\\d*\\.\\d+|\\d+\", lower).group()\n",
    "    upper_str = re.search(\"\\d*\\.\\d+|\\d+\", upper).group()\n",
    "    # note: what about european decimal notation?\n",
    "    # also note: what if multiple groups K50.1J8.4-etc\n",
    "\n",
    "\n",
    "    lower_num = int(lower_str.replace('.',''))\n",
    "    upper_num = int(upper_str.replace('.','')) +1\n",
    "    \n",
    "    if upper_num<lower_num:\n",
    "      raise ValueError('The start code cannot have a higher number than the end code')\n",
    "\n",
    "    # remember length in case of leading zeros \n",
    "    length = len(lower_str)\n",
    "\n",
    "    nums = range(lower_num, upper_num)\n",
    "\n",
    "    # must use integers in a loop, not floats\n",
    "    # which also means that we must multiply and divide to get decimal back\n",
    "    # and take care of leading and trailing zeros that may disappear\n",
    "    if '.' in lower_str:\n",
    "      lower_decimals = len(lower_str.split('.')[1])\n",
    "      upper_decimals = len(upper_str.split('.')[1])\n",
    "      if lower_decimals==upper_decimals:\n",
    "        multiplier = 10**lower_decimals\n",
    "        codes = [lower.replace(lower_str, format(num /multiplier, f'.{lower_decimals}f').zfill(length)) for num in nums]\n",
    "      # special case: allow k1.1-k1.123, but not k.1-k2.123 the last is ambigious: should it list k2.0 only 2.00?\n",
    "      elif (lower_decimals<upper_decimals) & (upper_str.split('.')[0]==lower_str.split('.')[0]):\n",
    "        from_decimal = int(lower_str.split('.')[1])\n",
    "        to_decimal = int(upper_str.split('.')[1]) +1\n",
    "        nums = range(from_decimal, to_decimal)\n",
    "        decimal_str = '.'+lower.split('.')[1]\n",
    "        codes = [lower.replace(decimal_str, '.'+str(num)) for num in nums]\n",
    "      else:\n",
    "        raise ValueError('The start code and the end code do not have the same number of decimals')\n",
    "    else:\n",
    "        codes = [lower.replace(lower_str, str(num).zfill(length)) for num in nums]\n",
    "    return codes\n",
    " \n",
    "\n",
    "# register the function to be used if if the input is a list of strings\n",
    "@expand_hyphen.register(list)\n",
    "def _(expr):\n",
    "  extended = []\n",
    "  for word in expr:\n",
    "    extended.extend(expand_hyphen(word))\n",
    "  return extended\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OU1AIHQiRJRn"
   },
   "source": [
    "## expand star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rb0AiMPhd0Nj"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# A function to expand a string with star notation (K50*) \n",
    "# to list of all codes starting with K50\n",
    "\n",
    "@singledispatch\n",
    "def expand_star(code, all_codes=None):\n",
    "  \"\"\"\n",
    "  Expand expressions with star notation to a list of all values with the specified pattern\n",
    "  \n",
    "  Args:\n",
    "    expr (str or list): Expression (or list of expressions) to be expanded\n",
    "    all_codes (list) : A list of all codes\n",
    "\n",
    "  Examples:\n",
    "    expand_star('K50*', all_codes=icd9)\n",
    "    expand_star('K*5', all_codes=icd9)\n",
    "    expand_star('*5', all_codes=icd9)\n",
    "\n",
    "  \"\"\"\n",
    "  raise ValueError('The argument must be a string or a list')\n",
    "\n",
    "@expand_star.register(str)\n",
    "def _(code, all_codes=None): \n",
    "  # return immediately if there is nothing to expand\n",
    "  if '*' not in code:\n",
    "    return [code]\n",
    "\n",
    "  start_str, end_str = code.split('*')\n",
    "\n",
    "  if start_str and end_str:\n",
    "    codes = {code for code in all_codes if (code.startswith(start_str) & code.endswith(end_str))}\n",
    "\n",
    "  if start_str:\n",
    "    codes = {code for code in all_codes if code.startswith(start_str)}\n",
    "  \n",
    "  if end_str:\n",
    "    codes = {code for code in all_codes if code.endswith(end_str)}\n",
    "\n",
    "  return sorted(list(codes))\n",
    "\n",
    "@expand_star.register(list)\n",
    "def _(code, all_codes=None):\n",
    "  \n",
    "  expanded=[]\n",
    "  for star_code in code:\n",
    "    new_codes = expand_star(star_code, all_codes=all_codes)\n",
    "    expanded.extend(new_codes)\n",
    "  \n",
    "  # uniqify in case some overlap\n",
    "  expanded = list(set(expanded))\n",
    "\n",
    "  return sorted(expanded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4T6rBQZsiwzT"
   },
   "source": [
    "## expand colon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KTHKj3y3__kn"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# function to get all codes in a list between the specified start and end code \n",
    "# Example: Get all codes between K40:L52\n",
    "\n",
    "@singledispatch\n",
    "def expand_colon(code, all_codes=None):\n",
    "  raise ValueError('The argument must be a string or a list')\n",
    "\n",
    "@expand_colon.register(str)\n",
    "def _(code, all_codes=None):\n",
    "  \"\"\"\n",
    "  Expand expressions with colon notation to a list of complete code names\n",
    "  code (str or list): Expression (or list of expressions) to be expanded\n",
    "  all_codes (list or array) : The list to slice from\n",
    "\n",
    "  Examples\n",
    "    K50:K52\n",
    "    K50.5:K52.19\n",
    "    A3.0:A9.3\n",
    "\n",
    "  Note: This is different from hyphen and star notation because it can handle \n",
    "  different code lengths and different number of decimals \n",
    "\n",
    "  \"\"\"\n",
    "  if ':' not in code:\n",
    "    return [code]\n",
    "  \n",
    "  startstr, endstr = code.split(':')\n",
    "  \n",
    "  # remove spaces\n",
    "  startstr = startstr.strip()\n",
    "  endstr =endstr.strip()\n",
    "\n",
    "  # find start and end position\n",
    "  startpos = all_codes.index(startstr)\n",
    "  endpos = all_codes.index(endstr) + 1\n",
    "  \n",
    "  # slice list\n",
    "  expanded = all_codes[startpos:endpos+1]\n",
    "\n",
    "  return expanded\n",
    "\n",
    "\n",
    "@expand_colon.register(list)\n",
    "def _(code, all_codes=None, regex=False): \n",
    "  expanded=[]\n",
    "\n",
    "  for cod in code:\n",
    "    new_codes = expand_colon(cod, all_codes=all_codes)\n",
    "    expanded.extend(new_codes)\n",
    "  \n",
    "  return expanded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_WwFa6iai3Wq"
   },
   "source": [
    "## expand regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NbPMX0yS4Hmj"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# Return all elements in a list that fits a regex pattern\n",
    "\n",
    "@singledispatch\n",
    "def expand_regex(code, all_codes):\n",
    "  raise ValueError('The argument must be a string or a list of strings')\n",
    "\n",
    "@expand_regex.register(str)\n",
    "def _(code, all_codes=None):\n",
    "  code_regex = re.compile(code)\n",
    "  expanded = {code for code in all_codes if code_regex.match(code)}\n",
    "  # uniqify\n",
    "  expanded = list(set(expanded))\n",
    "  return expanded\n",
    "\n",
    "@expand_regex.register(list)\n",
    "def _(code, all_codes):  \n",
    "  expanded=[]\n",
    "\n",
    "  for cod in code:\n",
    "    new_codes = expand_regex(cod, all_codes=all_codes)\n",
    "    expanded.extend(new_codes)\n",
    "  \n",
    "  # uniqify in case some overlap\n",
    "  expanded = sorted(list(set(expanded)))\n",
    "\n",
    "  return expanded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iNZymQRsi8oW"
   },
   "source": [
    "## expand code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RpZQsDVgu1hr"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "@singledispatch\n",
    "def expand_code(code, all_codes=None, \n",
    "                hyphen=True, star=True, colon=True, regex=False, \n",
    "                drop_dot=False, drop_leading_zero=False,\n",
    "                sort_unique=True):\n",
    "  raise ValueError('The argument must be a string or a list of strings')\n",
    "\n",
    "@expand_code.register(str)\n",
    "def _(code, all_codes=None, \n",
    "      hyphen=True, star=True, colon=True, regex=False, \n",
    "      drop_dot=False, drop_leading_zero=False,\n",
    "      sort_unique=True):\n",
    "  #validating input\n",
    "  if (not regex) and (':' in code) and (('-' in code) or ('*' in code)):\n",
    "    raise ValueError('Notation using colon must start from and end in specific codes, not codes using star or hyphen')\n",
    "\n",
    "  if regex:\n",
    "    codes = expand_regex(code, all_codes=all_codes)\n",
    "    return codes\n",
    "  \n",
    "  if drop_dot:\n",
    "    code = del_dot(code)\n",
    "  \n",
    "  codes=[code]\n",
    "\n",
    "  if hyphen:\n",
    "    codes=expand_hyphen(code)\n",
    "  if star:\n",
    "    codes=expand_star(codes, all_codes=all_codes)\n",
    "  if colon:\n",
    "    codes=expand_colon(codes, all_codes=all_codes)\n",
    "\n",
    "  if sort_unique:\n",
    "    codes = sorted(list(set(codes)))\n",
    "\n",
    "  return codes\n",
    "\n",
    "@expand_code.register(list)\n",
    "def _(code, all_codes=None, hyphen=True, star=True, colon=True, regex=False, \n",
    "      drop_dot=False, drop_leading_zero=False,\n",
    "      sort_unique=True):\n",
    "  \n",
    "  expanded=[]\n",
    "\n",
    "  for cod in code:\n",
    "    new_codes = expand_code(cod, all_codes=all_codes, hyphen=hyphen, star=star, colon=colon, regex=regex, drop_dot=drop_dot, drop_leading_zero=drop_leading_zero)\n",
    "    expanded.extend(new_codes)\n",
    "  \n",
    "  # uniqify in case some overlap\n",
    "  expanded = list(set(expanded))\n",
    "\n",
    "  return sorted(expanded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q4E02nphLRAH"
   },
   "source": [
    "## expand columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PaSOcMjQLYHf"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def expand_columns(expr, all_columns=None, df=None, star=True, \n",
    "                   hyphen=True, colon=True, regex=None, info=None):\n",
    "    \"\"\"\n",
    "    Expand columns with special notation to their full column names\n",
    "\n",
    "    \"\"\"\n",
    "    notations = '* - :'.split()\n",
    "    # return immediately if not needed\n",
    "    if not any(symbol in expr for symbol in notations):\n",
    "      return [expr]\n",
    "\n",
    "    # get a list of columns of it is only implicity defined by the df\n",
    "    # warning: may depreciate this, require explicit all_columns\n",
    "    if df & (not all_columns):\n",
    "      all_columns=list(df.columns)\n",
    "\n",
    "    if regex:\n",
    "      cols = [col for col in all_columns if re.match(regex, expr)]\n",
    "    else:\n",
    "      if hyphen:\n",
    "        cols = expand_hyphen(expr)\n",
    "      if star:\n",
    "        cols = expand_star(expr, all_codes=all_columns)\n",
    "      if colon:\n",
    "        cols = expand_colon(expr, all_codes=all_columns)\n",
    "\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sBlNB_bjFa0I"
   },
   "source": [
    "# More helper functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cki3g2TkTPPY"
   },
   "source": [
    "## get rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sqIDq3lEiGsL"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# mark rows that contain certain codes in one or more colums\n",
    "def get_rows(df, codes, cols=None, sep=None, pid='pid', info=None, fix=True):\n",
    "  \"\"\"\n",
    "  Make a boolean series that is true for all rows that contain the codes\n",
    "  \n",
    "  Args\n",
    "    df (dataframe or series): The dataframe with codes\n",
    "    codes (str, list, set, dict): codes to be counted\n",
    "    cols (str or list): list of columns to search in\n",
    "    sep (str): The symbol that seperates the codes if there are multiple codes in a cell\n",
    "    pid (str): The name of the column with the personal identifier\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  # check if evaluated previously\n",
    "  info, rows = memory(info=info, func = 'get_rows', expr=codes)\n",
    "  if rows:\n",
    "    return rows\n",
    "\n",
    "  # check if codes and columns need to be expanded (needed if they use notation) \n",
    "  if fix:\n",
    "    # do this when if cols exist, but if it does not ...\n",
    "    cols = expand_columns(expr=cols, all_columns=list(df.columns), info=info)\n",
    "    all_codes = sorted(unique(df=df, cols=cols, sep=sep))\n",
    "    codes = expand_code(codes, all_codes=all_codes)\n",
    "\n",
    "  # codes and cols should be lists\n",
    "  codes = listify(codes)\n",
    "  cols = listify(cols)\n",
    "  \n",
    "  # approach depends on whether we have multi-value cells or not\n",
    "  # if sep exist, then have multi-value cells\n",
    "  if sep:\n",
    "    # have multi-valued cells\n",
    "    # note: this assumes the sep is a regex word delimiter\n",
    "    codes = [rf'\\b{code}\\b' for code in codes]\n",
    "    codes_regex = '|'.join(codes)\n",
    "    \n",
    "    # starting point: no codes have been found\n",
    "    # needed since otherwise the function might return None if no codes exist\n",
    "    rows = pd.Series(False*len(df),index=df.index)\n",
    "\n",
    "   # loop over all columns and mark when a code exist  \n",
    "    for col in cols:\n",
    "      rows=rows | df[col].str.contains(codes_regex, na=False)\n",
    "  \n",
    "  # if not multi valued cells\n",
    "  else:\n",
    "    mask = df[cols].isin(codes)\n",
    "    rows = mask.any(axis=1)\n",
    "  return rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hBFksM_qU2Lv"
   },
   "source": [
    "## make codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "96CSiOu7ied9"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def make_codes(n, letters=26, numbers=100, seed=False):\n",
    "  \"\"\"\n",
    "  Generate a dataframe with a column of random codes\n",
    "  \n",
    "  Args:\n",
    "    letters (int): The number of different letters to use\n",
    "    numbers (int): The number of different numbers to use\n",
    "\n",
    "  Returns\n",
    "    A dataframe with a column with one or more codes in the rows\n",
    "\n",
    "  \"\"\"\n",
    "  # each code is assumed to consist of a letter and a number\n",
    "  alphabet = list('abcdefghigjklmnopqrstuvwxyz')\n",
    "  letters=alphabet[:letters+1]\n",
    "  \n",
    "  # make random numbers same if seed is specified\n",
    "  if seed:\n",
    "    np.random.seed(0)\n",
    "\n",
    "  # determine the number of codes to be drawn for each event\n",
    "  n_codes=np.random.negative_binomial(1, p=0.3, size=n)\n",
    "  # avoid zero (all events have to have at least one code)\n",
    "  n_codes=n_codes+1\n",
    "  \n",
    "  # for each event, randomly generate a the number of codes specified by n_codes\n",
    "  codes=[]\n",
    "  for i in n_codes:\n",
    "      diag = [np.random.choice(letters).upper()+\n",
    "              str(int(np.random.uniform(low=1, high=numbers))) \n",
    "              for num in range(i)]\n",
    "\n",
    "      code_string=','.join(diag)\n",
    "      codes.append(code_string)\n",
    "\n",
    "  # create a dataframe based on the list   \n",
    "  df=pd.DataFrame(codes)    \n",
    "  df.columns=['code']\n",
    "  \n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f6Aej2nRyVX4"
   },
   "outputs": [],
   "source": [
    "make_codes(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gsxSAgv_VKr4"
   },
   "source": [
    "## make data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K3H5egzAjapK"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def make_data(n, letters=26, numbers=100, seed=False):\n",
    "  \"\"\"\n",
    "  Generate a dataframe with a column of random codes\n",
    "  \n",
    "  Args:\n",
    "    letters (int): The number of different letters to use\n",
    "    numbers (int): The number of different numbers to use\n",
    "\n",
    "  Returns\n",
    "    A dataframe with a column with one or more codes in the rows\n",
    "\n",
    "  \"\"\"\n",
    "  pid = range(n)\n",
    "  df_person=pd.DataFrame(index = pid)\n",
    "\n",
    "  #female = np.random.binomial(1, 0.5, size =n)\n",
    "  gender = np.random.choice(['male', 'female'], size=n)\n",
    "  region = np.random.choice(['north', 'south', 'east', 'west'], size=n)\n",
    "  birth_year = np.random.randint(1920, 1980, size=n)\n",
    "  birth_month = np.random.randint(1,12, size=n)\n",
    "  birth_day = np.random.randint(1,28, size=n) # ok, I know!\n",
    "  events_per_year = np.random.poisson(1, size=n)\n",
    "  years = 2020 - birth_year\n",
    "  events = years * events_per_year \n",
    "  events = np.where(events==0,1,events) \n",
    "  events = events.astype(int)\n",
    "  all_codes=[]\n",
    "  codes = [all_codes.extend(make_codes(n=n, letters=letters, \n",
    "                                       numbers=numbers, \n",
    "                                       seed=seed)['code'].tolist()) \n",
    "          for n in events]\n",
    "\n",
    "  days_alive = (2020 - birth_year) *365\n",
    "\n",
    "  days_and_events = zip(days_alive.tolist(), events.tolist())\n",
    "  all_days=[]\n",
    "  days_after_birth = [all_days.extend(np.random.randint(0, max_day, size=n)) for max_day, n in days_and_events]\n",
    "  pid_and_events = zip(list(pid), events.tolist())\n",
    "  all_pids=[]\n",
    "  pids = [all_pids.extend([p+1]*e) for p, e in pid_and_events]\n",
    "\n",
    "  df_events = pd.DataFrame(index=all_pids)\n",
    "  df_events['codes'] = all_codes\n",
    "  df_events['days_after'] = all_days \n",
    "\n",
    "  #df_person['female'] = female\n",
    "  df_person['gender'] = gender\n",
    "\n",
    "  df_person['region'] = region\n",
    "  df_person['year'] = birth_year\n",
    "  df_person['month'] = birth_month\n",
    "  df_person['day'] = birth_day\n",
    "  df = df_events.merge(df_person, left_index=True, right_index=True)\n",
    "  df['birth_date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "  df['event_date'] = df['birth_date'] + pd.to_timedelta(df.days_after, unit='d')\n",
    "  del df['month']\n",
    "  del df['day']\n",
    "  del df['days_after']\n",
    "  df['pid'] = df.index\n",
    "  df.index_name = 'pid_index'\n",
    "  df=df[['pid', 'gender', 'birth_date', 'event_date', 'region', 'codes']]\n",
    "  # include deaths too?\n",
    "  return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AEo-95j2ydvm"
   },
   "outputs": [],
   "source": [
    "#df = make_data(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AX_5I3DKwZhO"
   },
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vd6PxB8Cwx2p"
   },
   "outputs": [],
   "source": [
    "#count_person('max 2 L35')\n",
    "#count_person('x before y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y-oIboIXyiGE"
   },
   "source": [
    "# formatting an expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EE_onI9Syhvl"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def format_expression(expr):\n",
    "  \"\"\"\n",
    "  formats and expressions do it can be evaluated\n",
    "  \"\"\"\n",
    "  original = expr.copy()\n",
    "  # easier to parse and split when space only exist between siginificant words\n",
    "  expr=_remove_space(expr)\n",
    "  \n",
    "  # insert external variables (maybe unnecessary?)\n",
    "  expr=_insert_external(expr)\n",
    "  \n",
    "  # if multiple options are specified in the expression, \n",
    "  # make one expression for each alternative specification\n",
    "  expr=_get_expressions(expr)\n",
    "\n",
    "  return exprs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gz5s8YJZn0Nk"
   },
   "source": [
    "## remove_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mo67Ze05n0wf"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def remove_space(expr):\n",
    "  no_space_before = r'(\\s)([<=>,])'\n",
    "  no_space_after = r'([<=>,])(\\s)'\n",
    "\n",
    "  expr = re.sub(no_space_before, r'\\2', expr)\n",
    "  expr = re.sub(no_space_after, r'\\1', expr)\n",
    "  return expr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OtfhATnV6IYV"
   },
   "source": [
    "## get_expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ye7xAqYZ5ETp"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def get_expressions(expr):\n",
    "  \"\"\"\n",
    "  Makes a list of all possible statements from an expression, all possible combination of expressions involving ?[x, y, z] that are in the expressions\n",
    "  \n",
    "  >>>expr = 'min ?[2,3,4] of (K50, K51) in icd inside ?[10, 20, 30] days before 4AB02 in ncmp'\n",
    "  >>>get_options(expr)\n",
    "\n",
    "  \"\"\"\n",
    "  original = expr\n",
    "\n",
    "  alternatives = re.findall('\\?(\\[.*?\\])', expr)\n",
    "  alt_list = [ast.literal_eval(alternative) for alternative in alternatives]\n",
    "\n",
    "  combinations = product(*alt_list)\n",
    "\n",
    "  all_expressions = []\n",
    "  for n, combination in enumerate(combinations):\n",
    "      new_expr = original\n",
    "      for i, value in enumerate(combination):\n",
    "          new_expr = new_expr.replace('?' + alternatives[i], str(value), 1)\n",
    "      all_expressions.extend([new_expr])\n",
    "\n",
    "  return all_expressions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J5zfWV8d5JqC"
   },
   "outputs": [],
   "source": [
    "expr = 'min ?[2,3,4] of (K50, K51) in icd inside ?[10, 20, 30] days before 4AB02 in ncmp'\n",
    "get_expressions(expr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "40vOED0gBIzs"
   },
   "source": [
    "## insert_external"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1TJu1M095GQo"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def insert_external(expr):\n",
    "  \"\"\"\n",
    "  Replaces variables prefixed with @ in the expression with the\n",
    "  value of the variable from the global namespace\n",
    "\n",
    "  Example:\n",
    "      x=['4AB02', '4AB04', '4AB06']\n",
    "      expr = '@x before 4AB02'\n",
    "      insert_external(expr)\n",
    "  \"\"\"\n",
    "  externals = [word.strip('@') for word in expr.split() if word.startswith('@')]\n",
    "  for external in externals:\n",
    "      tmp = globals()[external]\n",
    "      expr = expr.replace(f'@{external} ', f'{tmp} ')\n",
    "  return expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K5KRuGdK7RQv"
   },
   "outputs": [],
   "source": [
    "  x_1=['4AB02', '4AB04', '4AB06']\n",
    "  expr = '@x_1 before 4AB02'\n",
    "  insert_external(expr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q-pgXeOspuMu"
   },
   "source": [
    "## insert columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Awh-x793WOhJ"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def insert_columns(expr, cols=None, all_cols=None, code2col_rules = None, info=None):\n",
    "    \"\"\"\n",
    "    insert column names in expressions (in col ...)\n",
    "    \n",
    "    logic: all conditions that do not contain column names, should end with an in statement\n",
    "    general approach: \n",
    "      - split on keywords to get each condition separately\n",
    "      - next: if the condition is about a column (age>20) no need to do anything\n",
    "      - if, not, check if it has an 'in', if not: insert one!\n",
    "     \n",
    "     todo/problem: row selectors? code2col rule (a function that you can pass in?), sniffing, dict option, or in info?\n",
    "\n",
    "    expr = 'max 2 of 4AB02 before 4AB04'\n",
    "    expr = 'max 2 of 4AB02 in x before 4AB04'\n",
    "\n",
    "    expr = '5th of 5th' # the code is here also a keyword ... problem - maybe of as long as we keep the of keyword ... but more difficult when we do not, at least for automatic column labeling!\n",
    "\n",
    "    expr = 'max 2 of 4AB0552 before 4AB04'\n",
    "\n",
    "    expr = 'max 2 of 4AB02 in ncmp' # should include zero ?\n",
    "    expr = 'min ?[1,2,3,4] of 4AB02 in ncmp'\n",
    "    expr = 'max ?[1,2,3,4] of 4AB02 in ncmp' # should include zero ?\n",
    "    expr = 'min 2 of days>4'\n",
    "    expr = 'min 8 of days>6'\n",
    "    expr = 'min 3 of 4AB02 in ncmp within 200 days'\n",
    "\n",
    "    insert_cols(expr, rule=col_rules)\n",
    "    \"\"\"\n",
    "\n",
    "    split_words = [' and ', ' or ', ' before ', ' after ', ' within ']\n",
    "\n",
    "    for word in split_words:\n",
    "      expr = expr.replace(word, f'@split@{word}')\n",
    "    conditions = expr.split('@split@')\n",
    "    \n",
    "    all_conditions=[]\n",
    "    for condition in conditions:\n",
    "      words = condition.split()\n",
    "      if re.match('[><=]', word):\n",
    "        pass\n",
    "      elif len(words)==1:\n",
    "        condition=condition + f' in {cols}'\n",
    "      elif ' in ' not in expr:\n",
    "        #alternative: words[-2] != 'in' but what if multiple cols already with spaces, then problem\n",
    "\n",
    "        condition=condition + f' in {cols}'\n",
    "      all_conditions.append(condition)\n",
    "    new_expr = \" \".join(all_conditions)\n",
    "    new_expr = new_expr.replace('@split@','')\n",
    "    return new_expr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XhqGRD37_A7I"
   },
   "source": [
    "# break up nested expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9omUvsMAp0U8"
   },
   "source": [
    "## outer parenthesis\n",
    "first whole parenthesis expression, from start to finish, including nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OaV5hupeXaoW"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def outer_parenthesis(expr):\n",
    "  \"\"\"\n",
    "  identifies the first  parenthesis expression\n",
    "  (may have nested parentheses inside it)\n",
    "  rerurns the content, or just the string if ther are no parentheses\n",
    "  may consider returning NONE then (if no?)\n",
    "\n",
    "  \"\"\"\n",
    "  start_pos=expr.find('(')\n",
    "  if start_pos == -1:\n",
    "      between = expr\n",
    "  else:\n",
    "      n=1\n",
    "      pos=start_pos\n",
    "      while n>0:\n",
    "          pos=pos+1\n",
    "          if expr[pos]=='(':\n",
    "              n=n+1\n",
    "          elif expr[pos]==')':\n",
    "              n=n-1\n",
    "          elif pos>len(expr):\n",
    "              print('Error: Not same number of opening and closing parenthesis')\n",
    "      between = expr[start_pos+1: pos]\n",
    "  return between\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "izIon8t5_Jh4"
   },
   "outputs": [],
   "source": [
    "\n",
    "expr=\"nothing\"\n",
    "expr=\"more(than nothing)\"\n",
    "expr=\"outside((nested) and (nested))\"\n",
    "expr=\"(x) and (y)\"\n",
    "expr = \"(x or q) before (y and z)\"\n",
    "expr = \"c1 before (y and z)\"\n",
    "\n",
    "\n",
    "outer_parenthesis(expr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o3PUWArTqNR-"
   },
   "source": [
    "## first inner parenthesis expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "noAh8JyM_Kln"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def first_inner_parenthesis(expr):\n",
    "  \"\"\"\n",
    "  iterates until it finds the (first) innermost expression surrounded by \n",
    "  parentheses and returns this expression\n",
    "  \"\"\"\n",
    "  new_expr = expr \n",
    "  \n",
    "  while '(' in new_expr:\n",
    "      outer= outer_parenthesis(new_expr)\n",
    "      new_expr = outer\n",
    "      #first_inner_parenthesis(new_expr) # hmm check why this is here    \n",
    "  return new_expr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wLMLldSH_NSD"
   },
   "outputs": [],
   "source": [
    " \n",
    "expr=\"nothing\"\n",
    "expr=\"more(than nothing)\"\n",
    "expr=\"outside((nested) and (nested))\"\n",
    "expr=\"(x) and (y)\"\n",
    "expr = \"(x or q) before (y and z)\"\n",
    "expr = \"c1 before (y and z)\"\n",
    "expr = \"(x and (a or b)) before (y and z)\"\n",
    "\n",
    "expr = \"(x and (a or (b after c))) before (y and z)\"\n",
    "expr = \"x and b and c\"\n",
    "\n",
    "first_inner_parenthesis(expr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uEca3D3drfuc"
   },
   "source": [
    "## break_up\n",
    "breaks an neste expresssion into its component parts\n",
    "\n",
    "returns a dictionary with the name and the expressions to be evaluated\n",
    "the dictionary is ordered: evaluate in order (since next expression may depend on calculation of previous expression)\n",
    "\n",
    "logic: recursively find the innnermost expresion, store it, substitute, repeat\n",
    "\n",
    "  possible todo (well, never! explicit is better than implicit here): implicit \n",
    "  breakup based on priority rules (and, or, before etc,\n",
    "  like multiplication addition atc have priority rules that allow implicit breakup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F7SA4MVX_OYk"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def break_up(expr):\n",
    "  \"\"\"\n",
    "  breaks up an expression with nested parenthesis into sub expressions with \n",
    "  no parenthesis, with the innermost expressions first, that needs to be \n",
    "  calculated before doing the outer expression. also replaces the statement with\n",
    "  a single symbol in the larger expression\n",
    "  \"\"\"\n",
    "\n",
    "  p=0\n",
    "  new_expr = expr\n",
    "  expr_store={}\n",
    "\n",
    "  while \"(\" in new_expr:\n",
    "      inner = first_inner_parenthesis(new_expr)\n",
    "      new_expr = new_expr.replace(f'({inner})', f'p{p}')\n",
    "      expr_store[f'p{p}'] = inner\n",
    "      p=p+1\n",
    "  return new_expr, expr_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EBiJrbDpsIaL"
   },
   "outputs": [],
   "source": [
    "expr=\"nothing\"\n",
    "expr=\"more(than nothing)\"\n",
    "expr=\"outside((nested) and (nested))\"\n",
    "expr=\"(x) and (y)\"\n",
    "expr = \"(x or q) before (y and z)\"\n",
    "expr = \"c1 before (y and z)\"\n",
    "expr = \"(x and (a or b)) before (y and z)\"\n",
    "\n",
    "expr = \"(x and (a or (b after c))) before (y and z)\"\n",
    "expr = \"x and b and c\"\n",
    "\n",
    "expr=\"outside and ((nested) and (nested))\"\n",
    "break_up(expr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KWzPU74Qx2WL"
   },
   "source": [
    "# eval stuff\n",
    "\n",
    "After formatting and fixing a query, we end up with a list of expressions to be evaluatd (eval_expr)\n",
    "\n",
    "After breaking up a standard expressions, we have a dictionary of sub expressions (X before Y, min 2 of X and max 3 of Y) (eval_sub_expr)\n",
    "\n",
    "To evaluate a sub-expression, we breake it up into atomic statements (min 2 of Y), evaluate these separately and then apply the transformations that are appropriate based on the type of sub-expression it is (and, before/after etc) (eval_atom)\n",
    "\n",
    "To evaluate an atom we use eval_row selection, get_rows and eval_prefix.\n",
    "\n",
    "Alternative language? Paragraph, sentence, statement, condition, compound, molecule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JeCGyOVdn49J"
   },
   "source": [
    "eval_expr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KuW47zH5oAwy"
   },
   "source": [
    "##eval expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7k0-KFPcx2M1"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def eval_expr(df, expr, cols=None, sep=None, out='series', info=None, fix=True):\n",
    "  # check if evaluated previously\n",
    "  if cols:\n",
    "    name = expr + out + str(cols)\n",
    "  else: \n",
    "    name = expr + out\n",
    "\n",
    "  info, rows = memory(info, 'eval_expr', name)\n",
    "  if rows:\n",
    "    return rows\n",
    "  \n",
    "  if fix:\n",
    "    expr = remove_space(expr)\n",
    "    expr = insert_external(expr)\n",
    "    expr = insert_columns(expr=expr, cols=cols, all_cols=list(df.columns))\n",
    "    #print(expr)\n",
    "\n",
    "  final_expr, sub_expressions = break_up(expr)\n",
    "\n",
    "  for name, expr in sub_expressions.items():\n",
    "    df[name] = eval_sub(df=df, expr=expr, cols=cols, sep=sep, info=info)\n",
    "  result = eval_sub(df=df, expr=final_expr, cols=cols, sep=sep, info=info)\n",
    "\n",
    "  # return boolean series person (default) or rows, or pids\n",
    "  if out == 'series':\n",
    "    result = result.any(level=0)\n",
    "  elif out == 'pids':\n",
    "    result = set(result.index[result])\n",
    "  \n",
    "  info.evaluated['eval_expr'][name] = result\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XRTPVcr-TqYf"
   },
   "source": [
    "## eval sub (expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "COvNwmvs0xIP"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def eval_sub(df, expr, cols=None, sep=None, info=None, fix=True):\n",
    "  # check if evaluated previously\n",
    "  if cols:\n",
    "    name = expr + str(cols)\n",
    "  else: \n",
    "    name = expr \n",
    "\n",
    "  info, rows = memory(info, 'eval_sub', name)\n",
    "  if rows:\n",
    "    return rows\n",
    "\n",
    "  splitwords = 'and or not within after before inside outside'.split()\n",
    "  operators = '= > <'.split()\n",
    "  \n",
    "  # a simple existence expression\n",
    "  if not any(word in expr for word in splitwords):\n",
    "    print('simple')\n",
    "    rows = eval_atom(df=df, expr=expr, sep=sep, info=info)\n",
    "  \n",
    "  # and/or epression (to do:allow multiple and or without parenthesis?)\n",
    "  # shortcut before splitting in sub_expressions: if only and or and not before etc: then can simplify: just split on and or, substitute, evaluate separate, keep parenthesis and do an eval\n",
    "  elif (' and ' in expr) or (' or ' in expr):\n",
    "    print('and or')\n",
    "    rows = eval_and_or(df=df, expr=expr, sep=sep, info = info)\n",
    "\n",
    "  # a before/after expression\n",
    "  elif any(word in expr for word in [' before ', ' after ', ' simultaneous ']):\n",
    "    print('before after')\n",
    "    rows = eval_before_after(df=df, condition=expr, sep=sep, info=info, fix=fix)\n",
    "  \n",
    "  # within, not within expression\n",
    "  elif ' within ' in expr:\n",
    "    rows = eval_within(df=df, expr=expr, sep=sep, info=info)\n",
    "\n",
    "  # an inside expression\n",
    "  elif (' inside ' in expr) or (' outside ' in expr):\n",
    "    rows = eval_inside_outside(df=df, expr=expr, sep=sep, info=info)\n",
    "\n",
    "  # store result for future\n",
    "  info.evaluated['eval_sub'][name] = rows\n",
    "\n",
    "  return rows\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lZUr_NoBA1yA"
   },
   "source": [
    "(1st g after s) > 20\n",
    "1st g after s > 20\n",
    "\n",
    "1st g after s\n",
    "g after s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UvIwhQnbA1tJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g5ikSH8eTiSr"
   },
   "source": [
    "## eval atom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eIWIbwjSdB45"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# atoms: [prefix] condition[row_selector] [in columns]\n",
    "def eval_atom(df, expr, cols=None, sep=None, info=None):\n",
    "  # precautionary move!\n",
    "  expr=expr.strip()\n",
    "  \n",
    "  # check if evaluated previously\n",
    "  if cols:\n",
    "    name = expr + str(cols)\n",
    "  else: \n",
    "    name = expr\n",
    "\n",
    "  info, rows = memory(info, 'eval_atom', name)\n",
    "  if rows:\n",
    "    return rows  \n",
    "\n",
    "  # check if it has a row selector, execute if so\n",
    "  if '[rows:' in expr:\n",
    "    row_selection = eval_row_selection(df=df, expr=expr)\n",
    "    df=df[row_selection]\n",
    "    # delete the row selector after applying it\n",
    "    before, after = expr.split('[rows:')\n",
    "    expr = before + after[1:]\n",
    "  \n",
    "  # starting point\n",
    "  prefix = None\n",
    "  words = expr.split()\n",
    "  operator = any(operator in expr for operator in list('=><'))\n",
    "  function_call = '(' in expr\n",
    "\n",
    "  # is the atom a code based atom? example K50.1\n",
    "  # code based atoms must have in or cols\n",
    "  if (cols) or ('in' in words):\n",
    "    if 'in' in words:\n",
    "      codes, cols = expr.split(' in ')\n",
    "      cols=cols.strip()\n",
    "    else:\n",
    "      codes = expr    \n",
    "    if len(words)>3:\n",
    "      prefix, codes = codes.rsplit(' ',1)\n",
    "\n",
    "    # handle multiple cols \n",
    "    # in icd0, icd1, icd3 or in [icd0, icd1, icd3]\n",
    "    if ',' in cols:\n",
    "      if cols.startswith('['):\n",
    "        cols = cols[1:-1].split(',')\n",
    "        cols=[col.strip() for col in cols]\n",
    "\n",
    "    # deal with list of codes [K50, K51]\n",
    "    if ',' in codes:\n",
    "      codes=codes[1:-1].split(',')\n",
    "      codes=[code.strip() for code in codes]\n",
    " \n",
    "    #expand codes and cols?\n",
    "    rows = get_rows(df=df, cols=cols, codes=codes, sep=sep, info=info)\n",
    "\n",
    "  # a simple column based atom: example glucose>8\n",
    "  elif (operator) and (not function_call):\n",
    "    prefix, expr = expr.rsplit(' ',1)\n",
    "    rows=df.eval(expr)\n",
    "\n",
    "  # a function based atom: example glucose.cumsum()>100\n",
    "  elif (operator) and (function_call):\n",
    "    prefix, expr = expr.rsplit(' ',1)\n",
    "    rows = pd.eval(f\"df.groupby('pid').{expr}\")\n",
    "    #alternative? rows = df.groupby(pid).apply(eval, expr)?\n",
    "  \n",
    "  if prefix:\n",
    "    rows = eval_prefix(prefix, rows)\n",
    "  \n",
    "  # store results for future\n",
    "  info.evaluated['eval_atom'][name] = rows\n",
    "  \n",
    "  return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3vq9XilsjQwK"
   },
   "outputs": [],
   "source": [
    "df=make_data(1000,letters=10, numbers=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jCwNb47opZ7P"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8f7_q0KEsuYE"
   },
   "outputs": [],
   "source": [
    "#df['prescription_code'] =df.codes.str.split(',', expand=True)[0]\n",
    "#df['ddd']=np.random.randint(1,99, size=len(df))\n",
    "#df.to_csv('/content/sample_prescriptions.csv')\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HkdfdlBVjQrj"
   },
   "outputs": [],
   "source": [
    "eval_atom(df=df, expr='E2 in codes', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c_li3l5yjB9z"
   },
   "source": [
    "## eval row selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q7fzoZ24n4G7"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def eval_row_selection(df, expr, sep=None, info=None):\n",
    "  \"\"\"\n",
    "  example K50[rows:age>20]\n",
    "  example min 2 K51[rows: after hip_surgery]\n",
    "  df[surgery_rows]....\n",
    "  min 2 K51 inside after hip surgery\n",
    "  min 2 K51 after hip surgery\n",
    "  after age>20?\n",
    "  \"\"\"\n",
    "  \n",
    "  # check if evaluated previously\n",
    "  info, rows = memory(info, 'eval_row_selection', expr)\n",
    "  if rows:\n",
    "    return rows \n",
    "\n",
    "  row_query = expr.split('[rows:')[1].split[']'][0]\n",
    "  \n",
    "  statement = any(operator in expr for operator in list('=><'))\n",
    "  temporal = (' days ' in expr) \n",
    "  positional = (' events ' in expr) or (' event ' in expr)\n",
    "  #positional = (expr.startswith('inside ')) or (expr.startswith('outside '))\n",
    "\n",
    "  # statement:'age>20'\n",
    "  if statement:\n",
    "    rows=df.eval(row_query)\n",
    "  # positional: 'inside/outside 5 events before/after/around X'\n",
    "  elif positional:\n",
    "    rows = create_time_interval(df=df, expr=expr,cols=cols, info=info)\n",
    "  # temporal: 'after 1st S4'\n",
    "  else:\n",
    "    rows = create_time_interval(df=df, expr=expr,cols=cols, info=info)\n",
    "\n",
    "  info.evaluated['eval_row_selection'][expr] = rows\n",
    "\n",
    "  return rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W8l1Bs_DS99I"
   },
   "source": [
    "## eval prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DnQJdxFkn5o6"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def eval_prefix(prefix, rows):\n",
    "  interval=True\n",
    "  freq = ['min ', 'max ', 'exactly ']\n",
    "  first_last = [' first ', ' last']\n",
    "  ordinal = r'(-?\\d+)(st|nd|rd|th)'  # re to find and split 3rd into 3 and rd etc\n",
    "\n",
    "  rowscum = rows.groupby(level=0).cumsum()\n",
    "\n",
    "  # freq condition: min 5 of 4A\n",
    "  if any(word in prefix for word in freq):\n",
    "    word, num = prefix.split()\n",
    "    num = int(num)\n",
    "\n",
    "    if 'min' in word:\n",
    "      select = (rowscum >= num)\n",
    "    elif 'max' in word:  # double check!\n",
    "      n_max = rowscum.max(level=0)\n",
    "      select = (n_max <= num)\n",
    "    elif 'exactly' in word:\n",
    "      select = (rowscum == num)\n",
    "\n",
    "  # beteween frequency or between ordinals (1st and 3rd)\n",
    "  # note: inclusive between\n",
    "  elif 'between ' in prefix:\n",
    "    word, lower,_, upper = prefix.split()\n",
    "    # interval/positional between 4th and 8th\n",
    "    if re.match(prefix, ordinal):\n",
    "        lower=int(lower[:-2])\n",
    "        upper=int(upper[:-2])\n",
    "        if lower > 0:\n",
    "            aboverows = (rowscum >= lower)\n",
    "        else:\n",
    "            aboverows = (lastrowscum >= abs(lower))\n",
    "\n",
    "        if upper > 0:\n",
    "            belowrows = (rowscum <= upper)\n",
    "        else:\n",
    "            belowrows = (lastrowscum <= abs(upper))\n",
    "\n",
    "        select = (aboverows & belowrows)\n",
    "    # frequency between: between 4 and 8 of 4AB02\n",
    "    else:\n",
    "      lower=int(lower)\n",
    "      upper=int(upper)\n",
    "      select = rowscum.between(lower, upper, inclusive=True)\n",
    "\n",
    "  # first, last range conditions: first 5 of 4A\n",
    "  elif any(word.strip() in prefix for word in first_last):  # regex is better\n",
    "    word, num = prefix.split()\n",
    "    if '%' not in num:\n",
    "      num = int(num)\n",
    "      if 'first' in word:\n",
    "        select = (rowscum <= num)\n",
    "      if 'last' in word:\n",
    "        select = (rowscum >= num)\n",
    "\n",
    "\n",
    "  # pct condition: first 10% of 4A\n",
    "  elif '%' in prefix:\n",
    "    n_max = rowscum.groupby(level=0).max()\n",
    "    pct = float(num.split(r'%')[0]) / 100\n",
    "    pid_num = n_max * pct\n",
    "\n",
    "    # first 1% of two observations includes 1st obs\n",
    "    pid_num[pid_num < 1] = 1\n",
    "\n",
    "    if word == 'first':\n",
    "      # hmm, generalproblem: drop if pid is missing ...\n",
    "      select = (rowscum < pid_num)\n",
    "\n",
    "    if word == 'last':\n",
    "      select = (rowscum > pid_num)\n",
    "\n",
    "  # percentile condition\n",
    "  elif ' percentile ' in prefix:\n",
    "    event_num = rows.groupby(level=0).cumcount()\n",
    "    n_count = rowscum.groupby(level=0).size()\n",
    "\n",
    "    num = float(num.split(r'%')[0]) / 100\n",
    "\n",
    "    pid_num = n_count * num\n",
    "\n",
    "    if word == 'first':\n",
    "      rows = (pid_num < event_num)\n",
    "\n",
    "    if word == 'last':\n",
    "      rows = (pid_num > event_num)\n",
    "  \n",
    "  # positional condition:  5th of 4a, 3rd to 8th of 4A, (3rd, 4th, 5th) of 4A\n",
    "  # also allows: 2nd last (or even -5th last)\n",
    "  elif re.match(ordinal, prefix):\n",
    "    pos_str = prefix.rsplit(' ',1)[0].strip('(').strip(')')\n",
    "    pos_nums = re.findall(ordinal, pos_str)\n",
    "    pos_nums = tuple([int(pos[0]) for pos in pos_nums])\n",
    "\n",
    "    # if the conditions includes last, need reversed cumsum\n",
    "    # example 2nd last\n",
    "    if ' last ' in pos_str or '-' in pos_str:\n",
    "      n_max = rowscum.groupby(level=0).max().add(1)\n",
    "      # reversed event number (by id)\n",
    "      lastrowscum = (rowscum - n_max).abs()\n",
    "      last_flag = 1\n",
    "    else:\n",
    "      last_flag = 0\n",
    "\n",
    "    # single position: 5th of 4A\n",
    "    if len(pos_nums) == 1:\n",
    "      interval = False\n",
    "      print('single position')\n",
    "      if last_flag:\n",
    "        select = (lastrowscum == pos_nums)\n",
    "      else:\n",
    "        select = (rowscum == pos_nums)\n",
    "\n",
    "    # from-to positions: 3rd to 8th of 4A, 1st to -3rd\n",
    "    elif ' to ' in pos_str:\n",
    "        lower, upper = pos_nums\n",
    "        if lower > 0:\n",
    "            aboverows = (rowscum >= lower)\n",
    "        else:\n",
    "            aboverows = (lastrowscum >= abs(lower))\n",
    "\n",
    "        if upper > 0:\n",
    "            belowrows = (rowscum <= upper)\n",
    "        else:\n",
    "            belowrows = (lastrowscum <= abs(upper))\n",
    "\n",
    "        select = (aboverows & belowrows)\n",
    "\n",
    "  # list of positions (3rd, 5th, 7th)\n",
    "  elif prefix.startswith('('):\n",
    "    pos_str = prefix.rsplit(' ',1)[0].strip().strip('(').strip(')')\n",
    "\n",
    "    pos_re = ordinal.replace(' ', '')  # last condition may have ) i.e. 25th)\n",
    "\n",
    "    pos_nums = re.findall(pos_re, pos_str)\n",
    "    pos_nums = tuple([int(pos[0]) for pos in pos_nums])\n",
    "\n",
    "    pos_num = [num for num in pos_nums if num > 0]\n",
    "    neg_num = [num for num in pos_nums if num < 0]\n",
    "\n",
    "    pos_select = rowscum.isin(pos_nums)\n",
    "    neg_select = rowscum.isin(pos_nums)\n",
    "    select = (pos_select | neg_select)\n",
    "\n",
    "  if interval==True:\n",
    "    return select\n",
    "  else:\n",
    "    return rows & select\n",
    "\n",
    "\n",
    "  # so far, have marked interval of events for expressions with qualifications\n",
    "  # (existence conditions are not intervals). example: First 5 of 4A, markes\n",
    "  # all events in the interval between the 1st and 5th of 4A\n",
    "  # if we only want to pick the 4A events in this intereval, we and it with\n",
    "  # the boolena for 4A existence (row). But sometimes we want to keep and use\n",
    "  # the interval. For instance when the qualifiers are used in before/after\n",
    "  # statements if the evaluated expression should be returned as 'exact row',\n",
    "  # 'interval row' or pid existence\n",
    "\n",
    " \n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wVJcLDboS4pU"
   },
   "source": [
    "testing prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aX9S3v_b0w8J"
   },
   "outputs": [],
   "source": [
    "index = np.random.randint(100, size=1000)\n",
    "code = np.random.binomial(1, p=0.4, size=1000)\n",
    "rows=pd.Series(code, index=index).sort_index()\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-GbGoupR3t_j"
   },
   "outputs": [],
   "source": [
    "df=rows.to_frame()\n",
    "df['evaluated_prefix'] =eval_prefix('2nd A', rows=rows)\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cJJmXVxBGnk5"
   },
   "source": [
    "## eval and or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_As5-L6dGoO2"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def eval_and_or(df, expr, sep=None, info=None):\n",
    "    split_words = [' and ', ' or ']\n",
    "\n",
    "    for word in split_words:\n",
    "      expr = expr.replace(word, f'@split@{word}')\n",
    "    conditions = expr.split('@split@')\n",
    "   \n",
    "    for n, condition in enumerate(conditions):\n",
    "      atom = condition.replace('and','').replace('or','')\n",
    "      name = c + str(n)\n",
    "      df[name] = eval_atom(df=df, expr=atom, sep=sep, info=info)\n",
    "      final_expr = final_expr + condition.replace(atom, name)\n",
    "   \n",
    "    rows = df.eval(final_expr)\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ry5jlnL73t6i"
   },
   "source": [
    "## eval before after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L1Dpuzja3tyt"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def eval_before_after(df, condition, cols=None, sep=None, \n",
    "                       info=None, out='pid', fix=True):\n",
    "    # check if evaluated previously\n",
    "    if cols:\n",
    "      name = condition + out + str(cols)\n",
    "    else: \n",
    "      name = condition + out\n",
    "  \n",
    "    info, rows = memory(info, 'eval_before_after', name)\n",
    "    if rows:\n",
    "      return rows \n",
    "\n",
    "    # replace conditions so intervals/multiples becomes positional\n",
    "    # example: before first 5 of 4A --> before 5th of 4A\n",
    "    # background: first 5 is not satisfied until ALL five have passed, while some other conditions are\n",
    "    # may introduce shortcuts for some easy/common evaluations later (like 4A before 4B, easier than 4st of 4A before 1st of 4B?)\n",
    "    # before and after are also different, may exploit this to create shortcuts\n",
    "    condition = re.sub(r'last (-?\\d+)', r'-\\1st', condition)  \n",
    "\n",
    "    condition = re.sub(r'first (-?\\d+)', r'\\1st', condition)\n",
    "    # todo: also fix percentile --> find position, not first 5 percent\n",
    "\n",
    "    before_expr, after_expr = re.split(' before | after | simultaneously ', condition)\n",
    "    print(f'{before_expr},{after_expr}')\n",
    "    # shortcut if ' simultaneous ' in condition: ...just a row and\n",
    "\n",
    "    # check if the left side of the before expression has been calculated\n",
    "    #if before in info.before_has_happened:\n",
    "    #    before_has_happened = info.before_has_happened[before]\n",
    "    #else:\n",
    "    before_has_happened = eval_atom(df=df, expr=before_expr, cols=cols, sep=sep, info=info).groupby(level=0).cumsum().astype(bool).astype(int)\n",
    "    #    info.before_has_happened[before] = before_has_happened\n",
    "  \n",
    "    # check if the right side of the before  expression have been calculated\n",
    "    #if after in info.after_has_happened:\n",
    "    #    after_has_happened = info.after_has_happened[after]\n",
    "    #else:\n",
    "    after_has_happened = eval_atom(df=df, expr=after_expr, cols=cols, sep=sep, info=info).groupby(level=0).cumsum().astype(bool).astype(int)\n",
    "    #    info.after_has_happened[after] = after_has_happened\n",
    "    \n",
    "    both_exist = (before_has_happened.any(level=0)) & (after_has_happened.any(level=0))\n",
    " \n",
    "    if ' before ' in condition:\n",
    "      is_it_before = (before_has_happened - after_has_happened).groupby(level=0).sum() \n",
    "      endrows = both_exist & (is_it_before > 0)\n",
    "    elif ' after ' in condition:\n",
    "      is_it_after = (after_has_happened - before_has_happened).groupby(level=0).sum() \n",
    "      endrows = both_exist & (is_it_after > 0)\n",
    "    elif ' simultaneous ' in condition:\n",
    "      difference = (before_has_happened - after_has_happened).groupby(level=0).sum()\n",
    "      endrows = both_exist & (difference ==0)\n",
    "    \n",
    "    #info.evaluated['eval_before_after'][name] = endrows\n",
    "\n",
    "    return endrows\n",
    "\n",
    "    \n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dI9VBaJFk_AG"
   },
   "source": [
    "## eval within\n",
    "\n",
    "Examples:\n",
    "    expr= '4AB02 within 100 days after 4AB04'\n",
    "    expr= 'min 2 of 4AB02 within 100 days'\n",
    "    expr= '4AB02 within 50 to 100 days before 4AB04'\n",
    "    expr= '4AB02 within 50 to 100 days before 4AB04'\n",
    "\n",
    "    # maybe use inside on some?\n",
    "\n",
    "    expr= 'min 4 of 4AB02 in ncmp within 100 days'\n",
    "\n",
    "    expr= 'min 2 of 4AB02 within last 100 days'\n",
    "\n",
    "    expr= 'min 2 of 4AB02 within 100 days from end'\n",
    "\n",
    "    expr= 'min 2 of 4AB02 within first 100 days'\n",
    "\n",
    "    expr= 'between 2 and 5 of 4AB02 within first 100 days' # avoid and? well, just use format and replace it with to?\n",
    "\n",
    "\n",
    "    expr= 'min 2 of 4AB02 within 100 days from beginning'\n",
    "\n",
    "    expr= 'min 2 of 4AB02 within 1st of 4AB04 to 5th of 4AB04'\n",
    "    expr= 'min 2 of 4AB02 within 1st of 4AB06 to 3rd of 4AB04'\n",
    "\n",
    "    expr= 'min 2 of 4AB02 within first 20 of 4AB04'\n",
    "\n",
    "    expr= '3rd of 4AB02 within first 20 of 4AB04'\n",
    "\n",
    "    expr= 'min 2 of 4AB02 within 100 days from 5th of 4AB04'\n",
    "    expr = '3 or more of 4ab within 100 days'\n",
    "    wstart, wend\n",
    "\n",
    "    expr= 'min 4 of 4AB02 in ncmp within 100 days'\n",
    "    expr= \"min 4 of ncmp=='4AB02' within 100 days\"\n",
    "    expr= \"at least 4 of ncmp=='4AB02' within 100 days\"\n",
    "    expr= \"more than 4 of ncmp=='4AB02' within 100 days\" # best language\n",
    "    expr= \"less than 4 of ncmp=='4AB02' within 100 days\" # best language\n",
    "    expr= \"between 4 and 7 of ncmp=='4AB02' within 100 days\" # best language inclusive or exclusive between\n",
    "    expr= \"5 or more of ncmp=='4AB02' within 100 days\" # best language\n",
    "    expr= \"from 4 to 7 of ncmp=='4AB02' within 100 days\" # best language\n",
    "    expr= \" 4 to 7 events with 4AB02 within 100 days\" # best language #events problem ... again format?\n",
    "    expr= \" from 4 to 7 events with 4AB02 within 100 days\" # best language #events problem ... again format?\n",
    "\n",
    "    expr= \" at least 5 events with 4AB02 within 100 days\" # best language #events problem ... again format?\n",
    "    expr= \" no more than 5 events with 4AB02 in ncmp within 100 days\" # best language #events problem ... again format?\n",
    "\n",
    "    expr= 'min 3 of days>3 within 100 days'\n",
    "\n",
    "    expr= 'ddd[pharma=='pharmaz'].sum()>97 within 100 days'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L7-utC1Sk63o"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def eval_within(df, condition, cols=None, sep=None, date='event_date', info=None, out='pid', pid='pid'):\n",
    "    \"\"\"\n",
    "    mark observations that satisfy the conditions in a within statement\n",
    "\n",
    "    examples: \n",
    "      - expr = 'min 3 4AB within 100 days'\n",
    "      - expr = '4AB02 in ncmp within 50 to 100 days before 4AB04 in ncmp'\n",
    "    \"\"\"\n",
    "    # within 100 days after 4AB --> within 0 to 100 days after 4AB\n",
    "    if ((' after ' in condition) or (' before ' in condition)) and not (' to ' in condition):\n",
    "      condition=condition.replace(' within ', ' within 0 to ')\n",
    "\n",
    "    left, right = condition.split(' within ')\n",
    "    print(f'within {left}, {right}')\n",
    "    \n",
    "\n",
    "    # within x to y days (better: between x to y days)\n",
    "    # expr='4AB02 in ncmp within 50 to 100 days before 4AB04 in ncmp'\n",
    "    if re.match(r'\\d+ to \\d+ ', right):\n",
    "        print(f'within x to y')\n",
    "        lower, _, upper, unit, direction, *rightsingle = right.split()\n",
    "        if direction == 'around':\n",
    "          condition = condition.replace(' around ', ' after ')\n",
    "          after_prows = eval_within(df=df, condition=condition, cols=cols, sep=sep, info=info)\n",
    "          condition = condition.replace(' after ', ' before ')\n",
    "          before_prows = eval_within(df=df, condition=condition, cols=cols, sep=sep, info=info)\n",
    "          endprows = (after_prows) | (before_prows)\n",
    "          return endprows\n",
    "\n",
    "        rightsingle = \" \".join(rightsingle)\n",
    "        lower = int(lower)\n",
    "        upper = int(upper)\n",
    "        \n",
    "        lrows = eval_atom(df=df, expr=left, cols=cols, sep=sep, info=info)\n",
    "        rrows = eval_atom(df=df, expr=rightsingle, cols=cols, sep=sep, info=info)\n",
    "\n",
    "        pid_change = ((df[pid] - df[pid].shift()) != 0)\n",
    "\n",
    "        rdates = df[date].where(rrows == 1, np.datetime64('NaT'))\n",
    "\n",
    "        # if not have a date assign one to avoid ffill from person above\n",
    "        # risky?\n",
    "        rdates[(pid_change & ~rrows)] = np.datetime64('2100-09-09')  \n",
    "              \n",
    "        if direction == 'after':\n",
    "            rdates = rdates.fillna(method='ffill')  # hmmm must use groupby here? or can it be avoided? inseret a 999 when pid change and fill it with nan after ffill?\n",
    "\n",
    "        elif direction == 'before':\n",
    "            rdates = rdates.fillna(method='bfill')\n",
    "\n",
    "        rdates = rdates.where(rdates != np.datetime64('2100-09-09'), np.datetime64('NaT'))\n",
    "\n",
    "        # allow other time units, within 5 seconds etc\n",
    "        if unit == 'days':\n",
    "            delta = (df[date] - rdates) / np.timedelta64(1, 'D')\n",
    "        else:\n",
    "            # add s if it is not there? like 1 day, 1 second?\n",
    "            delta = (df[date] - rdates)\n",
    "            delta = getattr(delta.dt, unit)\n",
    "\n",
    "        if direction == 'before':\n",
    "            delta = delta.abs()\n",
    "        within = (delta >= lower) & (delta <= upper)\n",
    "        endrows = (lrows & within) # nb, frequency conditions not work here I think: min 3 x within 10 to 100 days before S\n",
    "        cpid = endrows.any(level=0)\n",
    "        \n",
    "\n",
    "    # pure within statements have few elements to the right\n",
    "    # example min 2 4AB within 100 days\n",
    "    elif len(right.split()) < 3:\n",
    "        print(f'within x days')\n",
    "        if ' in ' in left:\n",
    "            word, num, codes, _, cols = left.split()\n",
    "            rows = get_rows(df=df, codes=codes, cols=cols, sep=sep, info=info)\n",
    "\n",
    "        #  'sum(days)>15 within 100 days' or 'min 5 of ddd>200 within 100 days'\n",
    "        #  expr='sum(days)>15 within 100 days'\n",
    "        elif re.search('[>=<]', left):\n",
    "            if 'sum(' in left:\n",
    "                # may want to create smaller dataframe first, if possible? focus on only some variable, columns, rows?\n",
    "                sub = df.set_index(date)  # assume column date exist, should also drop rows with no time\n",
    "                col, operator = left.split(')')\n",
    "                col = col.replace('sum(', '').strip(')')\n",
    "                threshold, unit = right.split()\n",
    "                if unit == 'days': unit = 'D'\n",
    "                eval_text = f\"(sub.groupby('pid')['{col}'].rolling('{threshold}{unit}').sum()){operator}\"\n",
    "                rows = pd.eval(eval_text, engine='python')\n",
    "                cpid = rows.any(level=0)\n",
    "                return cpid\n",
    "            # 'min 5 ddd>200 within 100 days'\n",
    "            else:\n",
    "                word, num, codes = left.split()\n",
    "                rows = df.eval(codes)  # so far no sumsum etc, only 4 events with sugar_level>10 within 100 days\n",
    "\n",
    "        # code expression not quantity expression\n",
    "        # example: min 3 G2 within 100 days\n",
    "        else:\n",
    "            word, num, codes = left.split()\n",
    "            cols = cols\n",
    "            rows = get_rows(df=df, codes=codes, cols=cols)\n",
    "\n",
    "        threshold, unit = right.split()\n",
    "        threshold = int(threshold)\n",
    "        num = int(num)\n",
    "\n",
    "        if word == 'max': num = num + 1\n",
    "\n",
    "        # may need to use expand cols to get the cols (not use cols expression here if it starred)\n",
    "        sub = df[date][rows].dropna().to_frame()\n",
    "        sub.columns = ['date']\n",
    "        sub['pid'] = sub.index\n",
    "        sub['shifted_date'] = sub['date'].shift(-num)\n",
    "        sub['shifted_pid'] = sub['pid'].shift(-num)\n",
    "        sub['diff_pid'] = (sub['pid'] - sub['shifted_pid'])\n",
    "        sub['same_pid'] = np.where(sub.diff_pid == 0, 1, 0)\n",
    "\n",
    "        sub = sub[sub.same_pid == 1]\n",
    "        # sub['shifted_date'] = sub['date'].groupby(level=0).shift(int(num))\n",
    "        # sub['shifted_pid'] = sub['pid'].groupby(level=0).shift(int(num))\n",
    "\n",
    "        # todo: allow for different units here, months, weeks, seconds etc\n",
    "        sub['diff_days'] = (sub['shifted_date'] - sub['date']) / np.timedelta64(1, 'D')\n",
    "\n",
    "        # sub[sub.same_pid == 1]['diff_days'].dropna()/np.datetime64(1, 'D')\n",
    "\n",
    "        if word == 'min':\n",
    "            endrows = (sub['diff_days'] <= threshold)\n",
    "            cpid = endrows.any(level=0)\n",
    "\n",
    "        elif word == 'max':\n",
    "            # n = df.index.nunique()\n",
    "            endrows = (sub['diff_days'] <= threshold)\n",
    "            cpid = ~endrows.any(level=0)\n",
    "\n",
    "        # revise max and exactly\n",
    "\n",
    "        elif word == 'exactly':\n",
    "            endrows = (sub['diff_days'] <= threshold)\n",
    "            n_max = endrows.groupby(level=0).sum()\n",
    "            endrows = n_max == threshold\n",
    "            cpid = endrows.any(level=0)\n",
    "\n",
    "    #        #todo (also need to change parsing then ...)\n",
    "    #        elif word=='between':\n",
    "    #            endrows=(sub['diff_days']<=threshold)\n",
    "    #            n_max = endrows.groupby(level=0).sum()\n",
    "    #            endrows = n_max == threshold\n",
    "    #            cpid = endrows.any(level=0)\n",
    "\n",
    "    return cpid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zkBvIJC8xdbz"
   },
   "source": [
    "## eval inside outside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M0ZCkOfRxc0G"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def eval_inside_outside(df, condition, cols=None, sep=None, pid='pid', info=None):\n",
    "  \"\"\"\n",
    "    mark observations that satisfy the conditions in an inside/outside statement\n",
    "    \n",
    "    'inside/within/outside 5 events days before/after/around x'\n",
    "\n",
    "    examples: \n",
    "      - expr = 'X inside 4 events after Y'\n",
    "      - expr = 'X inside 4 events after each Y'\n",
    "      - expr = 'always X inside 4 events after each Y'\n",
    "      - expr = 'always X inside 4 events after a Y'\n",
    "      - expr = 'X inside 3 events around Y'\n",
    "      - expr = 'X outside 5 events after Y'\n",
    "      - expr = 'no X before last 5 events' - hmm this is before after, not inside?\n",
    "      - expr = 'no X inside 5 events before Y'   \n",
    "\n",
    "      - expr = 'min 3 4AB inside last 5 events' - special\n",
    "      - expr = 'X inside 1st and 5th Y' (between is better?) -special\n",
    "      - expr = 'X inside 2 events before and 8 events after Y' - special\n",
    "\n",
    "      - expr = 'min 2 X inside 4 events after Y'\n",
    "      - expr = 'X inside 4 events after min 3 Y'\n",
    "      - expr = 'X inside 4 to 7 events after min 3 Y'\n",
    "  \"\"\"\n",
    "  # some horrible parsing\n",
    "  if ' not ' in expr:\n",
    "    pre, negate, post = expr.partition(' not ', expr)\n",
    "    post='not ' + post\n",
    "  else:\n",
    "    pre, post = re.split(' inside | outside ', expr)\n",
    "    if ' inside ' in expr:\n",
    "      post = 'inside ' + post\n",
    "    else:\n",
    "      post = 'outside ' + post\n",
    "  \n",
    "  # mark relevant rows\n",
    "  inside_rows = create_position_interval(df=df, expr=post, sep=sep, info=info)\n",
    "\n",
    "  first_atom = eval_atom(df=df, expr=pre, sep=sep, info=info)\n",
    "\n",
    "  endrows = inside_rows & first_atom\n",
    "  # todo: warning, frequency conditions not work (at least not as expected)\n",
    "  # todo: make a frequency version work? different keywords/sytax? groupby?\n",
    "  return endrows\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J_S0_pCSxis-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-vgLO7tmxipk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a2pEIvIMk6nN"
   },
   "outputs": [],
   "source": [
    "#expr='G4 in codes within 1 to 800 days around 3rd G2 in codes'\n",
    "#a=eval_within(df=df, condition=expr, cols='codes', sep=',')\n",
    "#df['a'] = a\n",
    "#a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vfOQAQIFxeMX"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xbQgDmUKDAOY"
   },
   "source": [
    "# row selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMHzttUeDJTH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G4Z_c7ymDBFX"
   },
   "source": [
    "Examples\n",
    "- after/before s\n",
    "- after 3rd 3s\n",
    "- between 5th and 6th s\n",
    "- within last 5 events\n",
    "- within 100 days after s\n",
    "- within 100 days after 2nd s\n",
    "- within 50 days around 3rd s\n",
    "- after min 3 s\n",
    "- after glucose\n",
    "- (pharma x after s) and (pharma y before pharma z)\n",
    "- g after 1st s >20\n",
    "- x before y after 2nd s\n",
    "- x before (y after 2nd s)\n",
    "- (x before y) after 2nd s\n",
    "- after 2nd s: x before y\n",
    "- x before (y before z)\n",
    "- x before (y and z) and (y before z)\n",
    "- (x before y) and (y before z)\n",
    "- (x before y) after z\n",
    "- x before y before z before q\n",
    "\n",
    "before after statemetns have to be solved from right to left?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kSZ5ljGXK4ti"
   },
   "outputs": [],
   "source": [
    "#def select_before_after(df, expr, sep=None, info=None):\n",
    "#  word, atom = expr.split(' '.1)\n",
    "#  rows = eval_atom(df=df, expr=expr. sep=sep, info=info)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sXWkydalDBih"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BKCv-AaZDCdf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dXyIcKL-DCS1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vK_1pB2sDCHl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RNnW9rx2fQOI"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def eval_before_after(df, condition, cols=None, sep=None, \n",
    "                       info=None, out='pid', fix=True):\n",
    "    # check if evaluated previously\n",
    "    if cols:\n",
    "      name = condition + out + str(cols)\n",
    "    else: \n",
    "      name = condition + out\n",
    "  \n",
    "    info, rows = memory(info, 'row_eval', name)\n",
    "    if rows:\n",
    "      return rows \n",
    "\n",
    "    # replace conditions so intervals/multiples becomes positional\n",
    "    # example: before first 5 of 4A --> before 5th of 4A\n",
    "    # background: first 5 is not satisfied until ALL five have passed, while some other conditions are\n",
    "    # may introduce shortcuts for some easy/common evaluations later (like 4A before 4B, easier than 4st of 4A before 1st of 4B?)\n",
    "    # before and after are also different, may exploit this to create shortcuts\n",
    "    condition = re.sub(r'last (-?\\d+)', r'-\\1st', condition)  \n",
    "\n",
    "    condition = re.sub(r'first (-?\\d+)', r'\\1st', condition)\n",
    "    # todo: also fix percentile --> find position, not first 5 percent\n",
    "\n",
    "    before_expr, after_expr = re.split(' before | after | simultaneously ', condition)\n",
    "    print(f'{before_expr},{after_expr}')\n",
    "    # shortcut if ' simultaneous ' in condition: ...just a row and\n",
    "\n",
    "    # check if the left side of the before expression has been calculated\n",
    "    #if before in info.before_has_happened:\n",
    "    #    before_has_happened = info.before_has_happened[before]\n",
    "    #else:\n",
    "    before_has_happened = eval_atom(df=df, expr=before_expr, cols=cols, sep=sep, info=info).groupby(level=0).cumsum().astype(bool).astype(int)\n",
    "    #    info.before_has_happened[before] = before_has_happened\n",
    "  \n",
    "    # check if the right side of the before  expression have been calculated\n",
    "    #if after in info.after_has_happened:\n",
    "    #    after_has_happened = info.after_has_happened[after]\n",
    "    #else:\n",
    "    after_has_happened = eval_atom(df=df, expr=after_expr, cols=cols, sep=sep, info=info).groupby(level=0).cumsum().astype(bool).astype(int)\n",
    "    #    info.after_has_happened[after] = after_has_happened\n",
    "    \n",
    "    both_exist = (before_has_happened.any(level=0)) & (after_has_happened.any(level=0))\n",
    " \n",
    "    if ' before ' in condition:\n",
    "      is_it_before = (before_has_happened - after_has_happened).groupby(level=0).sum() \n",
    "      endrows = both_exist & (is_it_before > 0)\n",
    "    elif ' after ' in condition:\n",
    "      is_it_after = (after_has_happened - before_has_happened).groupby(level=0).sum() \n",
    "      endrows = both_exist & (is_it_after > 0)\n",
    "    elif ' simultaneous ' in condition:\n",
    "      difference = (before_has_happened - after_has_happened).groupby(level=0).sum()\n",
    "      endrows = both_exist & (difference ==0)\n",
    "    \n",
    "    info.evaluated['eval_before_after'][name] = endrows\n",
    "\n",
    "    return endrows\n",
    "\n",
    "    \n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BK7lzeTnyGtt"
   },
   "source": [
    "## eval selector prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BCj-H4z8euS7"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def eval_selector_prefix(df, prefix, sep=None, cols=None, date='date', info=None):\n",
    "  prefix=prefix.strip()\n",
    "  words = prefix.split()\n",
    "  \n",
    "  # before last 5 events\n",
    "  if ' event' in prefix:\n",
    "    prefix = prefix.replace('events', 'event')\n",
    "    #ad hoc, works with little code, but slow, optimize later\n",
    "    df['event'] = 'e'\n",
    "    prefix = prefix.replace('event', 'e in event')\n",
    "  \n",
    "  # just before\n",
    "  if prefix=='before':\n",
    "    print(prefix)\n",
    "    rows=~(df['rowscum']>0)\n",
    "  \n",
    "  # just after\n",
    "  elif prefix=='after':\n",
    "    print(prefix)\n",
    "    rows=df['rowscum']>0\n",
    "  \n",
    "  # 100 days before\n",
    "  elif words[1]=='days':\n",
    "    days, _, direction = prefix.split()\n",
    "    rows=mark_days(df=df, max_days=days, direction=direction, date=date, info=info)\n",
    "\n",
    "  # 3 events after\n",
    "  elif (words[1]=='events') or (words[1]=='event'):\n",
    "    days, _, direction = prefix.split()\n",
    "    rows=mark_events(rows=df['atom_rows'], max_event=days, direction=direction, info=info)\n",
    "  \n",
    "  # 50 to 100 days after\n",
    "  elif ('to' in words) and ('days' in words):            \n",
    "    min_days, _, max_days, unit, direction = prefix.split()\n",
    "    rows = mark_days(df=df, min_days=min_days, max_days=max_days, direction=direction) \n",
    "  \n",
    "  # 2 to 5 events after\n",
    "  elif ('to' in words) and (words[1]=='events') or (words[1]=='event'):            \n",
    "    min_events, _, max_events, unit, direction = prefix.split()\n",
    "    rows = mark_events(rows=df['atom_rows'], min_events=min_days, max_events=max_days, direction=direction) \n",
    "  \n",
    "  return rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xWp_Dj6iH-BV"
   },
   "source": [
    "## create time interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gqpPTbUAetb2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2zW4gVarXooX"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def create_time_intervals(df, expr, cols=None, sep=None, date='date', info=None):\n",
    "  \"\"\"\n",
    "  expr='before 4AB04 in ncmp'\n",
    "  expr='100 days before 4AB04 in ncmp'\n",
    "  expr='50 to 100 days after 4AB04 in ncmp'\n",
    "  \n",
    "  expr='5 to 10 events after 4AB04 in ncmp'\n",
    "  \n",
    "  expr='50 days around 4AB04 in ncmp'\n",
    "  expr='5 events around 4AB04 in ncmp' #next x events, inside 1 event after\n",
    "  expr='before 3rd 4AB04 in ncmp'\n",
    "  \n",
    "  expr='100 days before last event'\n",
    "  \n",
    "  expr='between 3rd s in cod and 7th b in cod'\n",
    "  \n",
    "  expr='before age>20'\n",
    "  expr='a pd statement' age >20\n",
    "  expr='100 days before last event'\n",
    "\n",
    "  expr='inside last 5 events'\n",
    "\n",
    "  create_time_intervals(df=df, expr=expr)\n",
    "  \"\"\"\n",
    "  original = expr\n",
    "  words = expr.split()\n",
    "\n",
    "  expr = re.sub(r'last (-?\\d+)', r'-\\1st', expr)  \n",
    "\n",
    "  expr = re.sub(r'first (-?\\d+)', r'\\1st', expr)\n",
    "\n",
    "  # todo: also fix percentile --> find position, not first 5 percent\n",
    "\n",
    "  if any(word in words for word in 'before after around'.split()):\n",
    "    splitted = re.split(r'\\bbefore\\b|\\bafter\\b|\\bsimultaneously\\b|\\baround\\b', expr)\n",
    "    atom = splitted[-1]\n",
    "    prefix=''\n",
    "    for word in words:\n",
    "      prefix = prefix + ' ' + word\n",
    "      if word in 'before after sametime around'.split():\n",
    "        break\n",
    "    print(atom, prefix)\n",
    "    atom_rows = eval_atom(df=df, expr=atom, cols=cols, sep=sep, info=info)\n",
    "    rowscum = atom_rows.groupby(level=0).cumsum()\n",
    "    df['atom_rows'] = atom_rows\n",
    "    df['rowscum'] = rowscum\n",
    "    rows = eval_selector_prefix(df=df, prefix=prefix, sep=sep, cols=cols, date=date, info=info)\n",
    "  return rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KPQKYi72ICZA"
   },
   "source": [
    "## mark days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U2yC3JE1Xp_5"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# mark days (ex 'within 22 days before/after x')\n",
    "def mark_days(df, direction, max_days, min_days=0,inside=True, date='date', info=None):\n",
    "  \"\"\"\n",
    "  mark days (ex 'inside/within/outside 22 days before/after/around x')\n",
    "  \"\"\"\n",
    "\n",
    "  df['reference_event'] = np.where(df['atom_rows'] == 1, df[date], np.datetime64('NaT'))\n",
    "  min_days=float(min_days)\n",
    "  max_days=float(max_days)\n",
    "  if direction=='around':\n",
    "    rows_before = mark_days(df=df, max_days=max_days, direction='before', date=date, inside=True)\n",
    "    rows_after = mark_days(df=df, max_days=max_days, direction='after', date=date, inside=True)\n",
    "    rows = rows_before | rows_after\n",
    "    if not inside: rows = ~rows\n",
    "    return rows\n",
    "\n",
    "  elif direction=='before':\n",
    "    df['reference_event'] = df['reference_event'].groupby(level=0).fillna(method='bfill')  \n",
    "  elif direction =='after':\n",
    "    df['reference_event'] = df['reference_event'].groupby(level=0).fillna(method='ffill')\n",
    "\n",
    "  event_diff = (df[date] - df['reference_event']).dt.days.abs() \n",
    "  \n",
    "  # inside 50 to 100 days before x\n",
    "  if inside:\n",
    "    rows = event_diff.between(min_days, max_days)\n",
    "  # outside 50 to 100 days before x\n",
    "  else:\n",
    "    rows = ~(event_diff.between(min_days, max_days))\n",
    "\n",
    "  return rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zXbdIuLPg8_F"
   },
   "source": [
    "## create position interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LcWChZ9x_G9P"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# mark rows (ex 'within 5 events before/after x')\n",
    "def create_position_interval(rows, expr, info=None):\n",
    "  \"\"\"\n",
    "  mark events (ex '(not,always, never) inside/within/outside 5 events before/after/around x')\n",
    "  \"\"\"\n",
    "  df = rows.to_frame()\n",
    "  df.columns = ['reference_event']\n",
    "  df['hard_way']=1\n",
    "  df['event_num'] = df.groupby(level=0)['hard_way'].cumsum()\n",
    "\n",
    "  pre, post = re.split(' inside | outside ', expr)\n",
    "  # to do: handle pre if it exists ... maybe only handle not (never and always is higher level)\n",
    "  \n",
    "  last_atom = re.split(' before | after | around', post)[-1]\n",
    "  \n",
    "  inside_statement = expr.replace(pre,'').replace(last_atom,'')\n",
    "\n",
    "  last_rows = eval_atom(df=df, expr=last_atom, cols=cols, sep=sep, info=info)\n",
    "\n",
    "  inside_statement = post.replace(last_atom,'')\n",
    "\n",
    "  # inside 2 to 5 events before x \n",
    "  # to do: validate since this should not work if the direction is around\n",
    "  if ' to ' in inside_statement:\n",
    "    in_or_out, min_events, _, max_events, direction =inside_statement.split()\n",
    "  # inside 5 events before x \n",
    "  else:\n",
    "    in_or_out, max_events, direction = inside_statement.split()\n",
    "  \n",
    "  if in_or_out in ('inside', 'between', 'not outside'):\n",
    "    inside = True\n",
    "  else:\n",
    "    inside = False\n",
    "\n",
    "  min_events=int(min_events)\n",
    "  max_events=int(max_events)\n",
    "\n",
    "  rows = mark_events(rows=last_rows, \n",
    "              direction=direction, \n",
    "              max_events=max_events, \n",
    "              min_events=min_events, \n",
    "              inside=inside, \n",
    "              info=info)\n",
    "\n",
    "  return rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zhNeGXuzBn0h"
   },
   "source": [
    "## mark events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_55TIPY6-fW8"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# mark rows (ex 'within 5 events before/after')\n",
    "def mark_events(rows, direction, max_events, min_events=0, inside=True, info=None):\n",
    "  \"\"\"\n",
    "  mark events (ex '(not,always, never) inside/within/outside 5 events before/after/around x')\n",
    "  \"\"\"\n",
    "  df = rows.to_frame()\n",
    "  df.columns = ['reference_event']\n",
    "  df['hard_way']=1\n",
    "  df['event_num'] = df.groupby(level=0)['hard_way'].cumsum()\n",
    "\n",
    "\n",
    "  min_events=int(min_events)\n",
    "  max_events=int(max_events)\n",
    "\n",
    "  if direction=='around':\n",
    "    rows_before = mark_events(df=df, max_events=max_events, direction='before')\n",
    "    rows_after = mark_events(df=df, max_events=max_events, direction='after')\n",
    "\n",
    "    rows = rows_before | rows_after\n",
    "    if not inside: rows = ~rows\n",
    "    return rows\n",
    "\n",
    "  elif direction=='before':\n",
    "    df['reference_event'] = df['reference_event'].groupby(level=0).fillna(method='bfill')  \n",
    "  elif direction =='after':\n",
    "    df['reference_event'] = df['reference_event'].groupby(level=0).fillna(method='ffill')\n",
    "\n",
    "  event_diff = (df['event_num'] - df['reference_event']).dt.days.abs() \n",
    "  \n",
    "  # inside 50 to 100 events before x\n",
    "  if inside:\n",
    "    rows = event_diff.between(min_events, max_events)\n",
    "  # outside 50 to 100 events before x\n",
    "  else:\n",
    "    rows = ~(event_diff.between(min_events, max_events))\n",
    "\n",
    "  return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zv2XcseP-JTC"
   },
   "outputs": [],
   "source": [
    "df=make_data(1000,letters=10, numbers=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HVGmSx7hB78X"
   },
   "outputs": [],
   "source": [
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GFi8JGVpFJxc"
   },
   "outputs": [],
   "source": [
    "df['date'] = df.event_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F3GFugOGNUZl"
   },
   "outputs": [],
   "source": [
    "df = df.sort_values(['pid', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g0r-Zh99dkGC"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WeP3lI-gi9_V"
   },
   "outputs": [],
   "source": [
    "row = eval_atom(df=df, expr='B2 in codes', sep=',')\n",
    "row.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GbldaVJCi9zq"
   },
   "outputs": [],
   "source": [
    "eval_row_selection(df=df, expr='2 events before I2 in codes', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aa1JoLQQ-8Un"
   },
   "outputs": [],
   "source": [
    "expr='before 4AB04 in ncmp'\n",
    "expr='100 days before 4AB04 in ncmp'\n",
    "expr='50 to 100 days after 4AB04 in ncmp'\n",
    "expr='before 3rd 4AB04 in ncmp'\n",
    "expr='100 days before last event'\n",
    "expr='after 1st D3 in codes'\n",
    "expr='100 days before D3 in codes'\n",
    "expr='500 days before H3 in codes'\n",
    "expr='900 days around H3 in codes'\n",
    "expr='100 to 600 days after H3 in codes' # interesting problem. is something is 150 days from a h3, but also 50 days from another h3?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-a6JG7X9wttI"
   },
   "outputs": [],
   "source": [
    "df['around']=create_time_intervals(df=df, expr=expr, sep=',')\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dDZ7YdSydHpl"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "99YZvoDwecvb"
   },
   "outputs": [],
   "source": [
    "df['atom_rows']=eval_atom(df=df, sep=',', expr='H4 in codes')\n",
    "df['atom_rows']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tBTBRj6RezYl"
   },
   "outputs": [],
   "source": [
    "df.groupby(level=0).atom_rows.cumsum()<1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tIW2-TR0-wRj"
   },
   "outputs": [],
   "source": [
    "create_time_intervals(df=df, expr=expr, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xZNyW3CtNg8K"
   },
   "outputs": [],
   "source": [
    "expr='before D3 in codes'\n",
    "x = re.split(r'\\bbefore\\b|\\bafter\\b|\\bsimultaneously\\b|\\baround\\b', expr)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C9QyERom-wKS"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iKFrMlAC-wAX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NHoLHlMd-v4M"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0qzjTrP_-vx0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4maMN_LHk6kU"
   },
   "outputs": [],
   "source": [
    "df=df.sort_values(['pid', 'event_date'])\n",
    "\n",
    "df['date'] = df.event_date\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b1VDBy27-kMm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LSflImKM-j8a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nD0Fn11zk6g0"
   },
   "outputs": [],
   "source": [
    "count_persons(df=df, expr='min ?[10, 20] G2 in codes', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8OB19gv1k6bt"
   },
   "outputs": [],
   "source": [
    "df.groupby('pid').size().value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ETKEDIMok6Ls"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NX1Xk-7bk6JP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aGe-uCcak6FC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DsQunD91k6An"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9eSxYwj-6Kc-"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def before_after(before, after, condition, info=None):\n",
    "\n",
    "    before_has_happened = before.groupby(level=0).cumsum().astype(bool).astype(int)\n",
    "    after_has_happened = after.groupby(level=0).cumsum().astype(bool).astype(int)\n",
    "\n",
    "    both_exist = (before_has_happened.any(level=0)) & (after_has_happened.any(level=0))\n",
    " \n",
    "    if condition=='before':\n",
    "      is_it_before = (before_has_happened - after_has_happened).groupby(level=0).sum() \n",
    "      endrows = both_exist & (is_it_before > 0)\n",
    "    elif condition=='after':\n",
    "      is_it_after = (after_has_happened - before_has_happened).groupby(level=0).sum() \n",
    "      endrows = both_exist & (is_it_after > 0)\n",
    "    elif condition == 'same time':\n",
    "      difference = (before_has_happened - after_has_happened).groupby(level=0).sum()\n",
    "      endrows = both_exist & (difference ==0)\n",
    "\n",
    "    \n",
    "    #expand to fit df length?\n",
    "    endrows =endrows.reindex(index=before.index)\n",
    "    #expand_endrows['result'] = endrows\n",
    "    #endrows = expand_endrows['result']\n",
    "    return endrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4StaCAdq6rAg"
   },
   "outputs": [],
   "source": [
    "index = np.random.randint(100, size=1000)\n",
    "code1 = np.random.binomial(1, p=0.8, size=1000)\n",
    "code2 = np.random.binomial(1, p=0.1, size=1000)\n",
    "\n",
    "df=pd.DataFrame(code1, index=index).sort_index()\n",
    "df['col2'] = code2\n",
    "df.columns =['col1', 'col2']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T4GHfPYJEOpD"
   },
   "outputs": [],
   "source": [
    "col1=df.col1\n",
    "col2=df.col2\n",
    "condition='before'\n",
    "df['before'] = before_after(col1, col2, condition)\n",
    "condition='after'\n",
    "df['after'] = before_after(col1, col2, condition)\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j7VksOTn6qoH"
   },
   "outputs": [],
   "source": [
    "df=make_data(1000,letters=10, numbers=5)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZHOnE6DAzbjd"
   },
   "source": [
    "# count persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2T9oYJkJk8-Z"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def count_persons(df, expr, cols=None, sep=None, codebook=None, info=None, use_caching=True, insert_cols=True, fix=True):\n",
    "    \"\"\"\n",
    "\n",
    "    count persons who satisfy the conditions in an expression\n",
    "\n",
    "    examples\n",
    "        expr = 'K50* in icd'\n",
    "        expr = 'K50* before K51*'\n",
    "        expr = '(K50 or K51) and K52'\n",
    "        expr = 'min 3 of glucose>8 within 100 days'\n",
    "        expr = '3rd of 4AB04 in ncmp before 3th of 4AB02 in ncmp'\n",
    "\n",
    "    \"\"\"\n",
    "    expr = remove_space(expr)\n",
    "    expr = insert_external(expr)\n",
    "    exprs = get_expressions(expr)\n",
    "\n",
    "    count = {}\n",
    "\n",
    "    for expr in exprs:\n",
    "      rows = eval_expr(df=df, expr=expr, cols=cols, sep=sep, info=info)\n",
    "      count[expr] = rows.any(level=0).sum()\n",
    "\n",
    "    # return only number if only one expression\n",
    "    if len(count) == 1:\n",
    "      return count[expr]\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MtCBnmSZgYg1"
   },
   "outputs": [],
   "source": [
    "count_persons(df=df, expr='G3 in codes before I2 in codes', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2CRXlpbWaRd0"
   },
   "outputs": [],
   "source": [
    "count_persons(df=df, expr='first 5 G3 before 3th G2', cols='codes', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HnwtW3gzam_y"
   },
   "outputs": [],
   "source": [
    "count_persons(df=df, expr='min 5 G3 before 3th G2', cols='codes', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "888gIqn2NYjy"
   },
   "outputs": [],
   "source": [
    "eval_atom(df=df, expr='1st G2 in codes', sep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KIJV2WmEc3cT"
   },
   "outputs": [],
   "source": [
    "insert_columns('G2', cols='codes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rtCa85Kb1SMD"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zxv9h9j_Gmh7"
   },
   "outputs": [],
   "source": [
    "count_persons(df=df, cols='codes', expr='B2 before H2', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o_q3lGUV1iKy"
   },
   "outputs": [],
   "source": [
    "df.codes.str.contains('G2', na=False).any(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tFMjQH6dgYas"
   },
   "outputs": [],
   "source": [
    "get_rows(df=df, codes='G2', cols='codes').any(level=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t4NTH_r9gYXT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IXXMtHQolXkw"
   },
   "outputs": [],
   "source": [
    "\n",
    "    expr = \"?['4AB02', '4AB04'] in ncmp\"\n",
    "    expr = '4AB02 in ncmp and 4AB04 in ncmp'\n",
    "    expr = 'min 10 of 4AB02 in ncmp'\n",
    "    expr = 'min ?[4,5,6] of 4AB02 in ncmp'\n",
    "    expr =  'min 6 of 4AB02 in ncmp'\n",
    "    expr =  'min 10 of 4AB02 in ncmp'\n",
    "\n",
    "    expr = 'min ?[6,8] of 4AB02 in ncmp'\n",
    "    expr = '1st of 4AB02 in ncmp'\n",
    "    expr = '2nd of 4AB02 in ncmp'\n",
    "\n",
    "    expr = '4AB02 in ncmp before 4AB04 in ncmp'\n",
    "    expr = '4AB04 in ncmp before 4AB02 in ncmp'\n",
    "    expr = '4AA23 in ncmp before 4AB02 in ncmp'\n",
    "    expr = 'max 2 of 4AB02 in ncmp before 4AB04 in ncmp'\n",
    "    expr = 'max 2 of 4AB02 in ncmp' # should include zero ?\n",
    "    expr = 'min ?[1,2,3,4] of 4AB02 in ncmp'\n",
    "    expr = 'max ?[1,2,3,4] of 4AB02 in ncmp' # should include zero ?\n",
    "    expr = 'min 2 of days>4'\n",
    "    expr = 'min 8 of days>6'\n",
    "    expr = 'min 3 of 4AB02 in ncmp within 200 days'\n",
    "\n",
    "    %time count_p(df=df, expr=expr, cols=None, codebook=None, info=None, sep=',')\n",
    "    %time count_p(df=df, expr=expr, cols=None, codebook=None, info=info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iuZ8iXjk6qlt"
   },
   "outputs": [],
   "source": [
    "def count_persons(df, codes=None, cols=None, pid='pid', sep=None,\n",
    "                  normalize=False, dropna=True, group=False, merge=False,\n",
    "                  length=None, groupby=None, codebook=None, fix=True):\n",
    "    \"\"\"\n",
    "    Counts number of individuals who are registered with given codes\n",
    "\n",
    "    Allows counting across multiple columns and multiple codes in the same\n",
    "    cells. For instance, there may be 10 diagnostic codes for one event (in\n",
    "    separate columns) and in some of the columns there may be more than one\n",
    "    diagnostic code (comma separated) and patient may have several such events\n",
    "    in the dataframe.\n",
    "\n",
    "    args:\n",
    "        codes (str, list or dict): Codes to be counted. Star and hyphen\n",
    "        notations are allowed. A dict can be used as input to merge codes\n",
    "        into larger categories before counting. The key is the name of\n",
    "        the category ('diabetes') and the value is a list of codes.\n",
    "\n",
    "            Examples:\n",
    "                codes=\"4ABA2\"\n",
    "                codes=\"4AB*\"\n",
    "                codes=['4AB2A', '4AB4A']\n",
    "                codes = {'diabetes' = ['34r32f', '3a*']}\n",
    "\n",
    "        cols (str or list): The column(s) with the codes. Star and colon\n",
    "        notation allowed.\n",
    "            Examples:\n",
    "                cols = 'icdmain'\n",
    "                cols = ['icdmain', 'icdside']\n",
    "                # all columns starting with 'icd'\n",
    "                cols = ['icd*'] # all columns starting with 'icd'\n",
    "                # all columns including and between icd1 and icd10\n",
    "                cols = ['icd1:icd10']\n",
    "\n",
    "        pid (str): Column name of the personal identifier\n",
    "        sep (str): The code seperator (if multiple codes in the same cells)\n",
    "        normalize (bool, default: False): If True, converts to pct\n",
    "        dropna (bool, default True): Include counts of how many did not get\n",
    "            any of the specified codes\n",
    "        length (int): If specified, will only use the number of characters\n",
    "            from each code as specified by the length parameter (useful to\n",
    "            count codes at different levels of granularity. For example,\n",
    "            sometimes oe wants to look at how many people get detailed codes,\n",
    "            other times the researcher wants to know only how many get general\n",
    "            atc codes, say the first four characters of the atc)\n",
    "\n",
    "    Examples\n",
    "        >>> df.atc.count_persons(codes='4AB04')\n",
    "\n",
    "        >>> df.atc.count_persons(codes='4AB04', dropna=False, normalize=True)\n",
    "\n",
    "        >>> df.atc.count_persons(codes=['4AB*', '4AC*'])\n",
    "\n",
    "        >>> df.atc.count_persons(codes=['4AB*', '4AC*'], group=True)\n",
    "        >>> df.atc.count_persons(codes=['4AB*', '4AC*'], group=True, merge=True)\n",
    "\n",
    "        >>> df.count_persons(codes={'adaliamumab':'4AB04'}, cols='ncmp', sep=',', pid='pid')\n",
    "\n",
    "        >>> df.count_persons(codes='4AB04', cols='ncmp', groupby=['disease', 'cohort'])\n",
    "\n",
    "        >>> df.groupby(['disease', 'cohort']).apply(count_persons, cols='ncmp', codes='4AB04', sep=',')\n",
    "\n",
    "    \"\"\"\n",
    "    sub = df\n",
    "    sub, cols = to_df(df=sub, cols=cols)\n",
    "    cols = expand_cols(df=sub, cols=cols)\n",
    "    if normalize:\n",
    "        sum_persons = sub[pid].nunique()\n",
    "\n",
    "    # if an expression instead of a codelist is used as input\n",
    "    if isinstance(codes, str) and codes.count(' ') > 1:\n",
    "        persons = use_expression(df=sub, expr=codes, cols=cols, sep=sep, out='persons', codebook=codebook, pid=pid)\n",
    "        if normalize:\n",
    "            counted = persons.sum() / len(persons)\n",
    "        else:\n",
    "            counted = persons.sum()\n",
    "\n",
    "\n",
    "    # if codes is a codelist (not an expression)\n",
    "    else:\n",
    "        if fix:\n",
    "            if not codes:\n",
    "                counted = count_persons_all_codes(df=sub, cols=cols, pid=pid, sep=sep,\n",
    "                                                   normalize=normalize, dropna=dropna, length=length, groupby=groupby)\n",
    "                return counted\n",
    "                # if some codes are specified, expand and format these, and reduce the df to the relevant codes\n",
    "            else:\n",
    "                # expands and formats columns and codes input\n",
    "                codes, cols, allcodes, sep = fix_args(df=sub, codes=codes, cols=cols, sep=sep, group=group,\n",
    "                                                       merge=merge)\n",
    "                rows = get_rows(df=sub, codes=allcodes, cols=cols, sep=sep, fix=False)\n",
    "                if not dropna:\n",
    "                    sum_persons = df[pid].nunique()\n",
    "                sub = sub[rows].set_index(pid,\n",
    "                                          drop=False)  # unsure if this is necessary, may drop it. Requred if method on a series? well not as long as we add pid column and recreate a series as a df\n",
    "\n",
    "        # make a df with the extracted codes\n",
    "        code_df = extract_codes(df=sub, codes=codes, cols=cols, sep=sep, fix=False, series=False)\n",
    "\n",
    "        labels = list(code_df.columns)\n",
    "\n",
    "        counted = pd.Series(index=labels)\n",
    "\n",
    "        # maybe delete groupby option, can be done outside df.groupby. apply ...\n",
    "        if groupby:\n",
    "            code_df = code_df.any(level=0)\n",
    "            sub_plevel = sub.groupby(pid)[groupby].first()\n",
    "            code_df = pd.concat([code_df, sub_plevel], axis=1)  # outer vs inner problem?\n",
    "\n",
    "            code_df = code_df.set_index(groupby)\n",
    "            counted = code_df.groupby(groupby).sum()\n",
    "\n",
    "        else:\n",
    "            for label in labels:\n",
    "                counted[label] = code_df[code_df[label]].index.nunique()\n",
    "\n",
    "        if not dropna:\n",
    "            with_codes = code_df.any(axis=1).any(level=0).sum()  # surprisingly time consuming?\n",
    "            nan_persons = persons - with_codes\n",
    "            counted['NaN'] = nan_persons\n",
    "\n",
    "        if normalize:\n",
    "            counted = counted / sum_persons\n",
    "        else:\n",
    "            counted = counted.astype(int)\n",
    "\n",
    "        if len(counted) == 1:\n",
    "            counted = counted.values[0]\n",
    "\n",
    "    return counted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G6RyetC16qiE"
   },
   "outputs": [],
   "source": [
    "eval_atom(df=df, expr='B1-B5 in codes', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xekit6CxwL6-"
   },
   "outputs": [],
   "source": [
    "def eval_condition(expr):\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2qCtIewwOTf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vfiz1tKWwOdt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_7RM2th4wOlo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z0-e-IURBGNP"
   },
   "outputs": [],
   "source": [
    "@lru_cache()\n",
    "def get_conditions(expr):\n",
    "    split_on = [' or ', ' and ']\n",
    "    split_rep = ' @split@ '\n",
    "    for split_word in split_on:\n",
    "        expr = expr.replace(split_word, split_rep)\n",
    "    conditions = expr.split(split_rep)\n",
    "    conditions = [condition.strip('(').strip(')') for condition in conditions]\n",
    "    return conditions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LQu3k92VfzuI"
   },
   "outputs": [],
   "source": [
    "expr = 'max 2 of 4AB0552 before 4AB04'\n",
    "_insert_columns(expr, 'icd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FzilGCxofznF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WOlBB0bYfzaw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BbfreWAgBGCh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uSFNflC9Xafn"
   },
   "source": [
    "# evaluating atomic expressions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e4CwrQ0GXacl"
   },
   "outputs": [],
   "source": [
    "def eval_single(df, condition, cols=None, sep=None, codebook=None,\n",
    "                out='pid', info=None):\n",
    "    \"\"\"\n",
    "    evaluates a single expressions (1st 4A),\n",
    "    not relational conditions (A before B, within 100 days after etc)\n",
    "\n",
    "    condition ='first 5 of 4AB02 in ncmp'\n",
    "    condition ='min 2 of days>10'\n",
    "    condition ='ddd>10'\n",
    "    condition ='ddd[4AB02 in codes]>10'\n",
    "    condition ='ddd[4AB02 in codes].cumsum()>50'\n",
    "    condition ='sum(ddd[4AB02 in codes])>50'\n",
    "\n",
    "    a=eval_single(df=npr, condition=condition, sep=',')\n",
    "\n",
    "    todo: info bank problems after allowing code selections?\n",
    "\n",
    "    \"\"\"\n",
    "    # create temporary storage to avoid recalculations\n",
    "    if not info: info = Info()\n",
    "\n",
    "    original_condition = condition\n",
    "\n",
    "    # no re-evaluation necessary if it it has been evaluated before\n",
    "    if out == 'pid' and (condition in info.single_pid):\n",
    "        return info.single_pid[condition]\n",
    "    elif out == 'rows' and (condition in info.single_rows):\n",
    "        return info.single_rows[condition]\n",
    "    elif out == 'interval' and (condition in info.single_interval):\n",
    "        return info.single_interval[condition]\n",
    "\n",
    "    quantity = r'[>=<]'  # better to use term comparison\n",
    "    freq = ['min ', 'max ', 'exactly ']\n",
    "    first_last_between = [' first ', ' last ', ' between ']\n",
    "    ordinal = r'(-?\\d+)(st |nd |rd |th )'  # re to find and split 3rd into 3 and rd etc\n",
    "\n",
    "    row_selection = ''\n",
    "\n",
    "    # select sub df if specified by [] after a code\n",
    "    if ('[' in condition) and (']' in condition):\n",
    "        row_query = condition.split('[')[-1].split(']')[0]\n",
    "        row_selection = row_query\n",
    "        # check if evaluated before\n",
    "        if row_query in info.single_rows:\n",
    "            rows = info.single_rows[row_query]\n",
    "        else:\n",
    "            condition = condition.replace(f'[{row_query}]', '')\n",
    "\n",
    "            if ' in ' in row_query:\n",
    "                row_query = row_query.replace(' in ', ' in: ')  # using old use_expresssion wich requires in with colon\n",
    "\n",
    "            relevant_rows = use_expression(df=df, cols=cols, expr=row_query, sep=sep)\n",
    "            info.single_rows[row_query] = relevant_rows\n",
    "        df = df[relevant_rows]\n",
    "\n",
    "    # is it a functional expression? ddd.cumsum()>10\n",
    "    # expr=\"ddd.cumsum()>10\"\n",
    "    # condition=expr\n",
    "    # expr='gender.nunique()==1'\n",
    "    # hmm what about properties like .is_monotonic? (no parenthesis!)\n",
    "    # if ('.' in condition) and ('(' in condition) and (')' in condition):\n",
    "    # still imperfect ... a code could also be a column name ... ok usually not also with a period mark in column name so ok\n",
    "    if ('.' in condition) and (condition.split('.')[0] in df.columns):\n",
    "        codetext = condition\n",
    "        codes = re.split('[<=>]', condition)[0]\n",
    "\n",
    "        if codes in info.single_rows:\n",
    "            rows = info.single_rows[codes]\n",
    "        # not evaluated before, so calc\n",
    "        else:\n",
    "            cols, funcexpr = condition.split('.')\n",
    "            # a method\n",
    "            if '(' in funcexpr:\n",
    "                func, threshold = funcexpr.split(')')\n",
    "                func, args = func.split('(')\n",
    "                rows = pd.eval(f\"tmpdf.groupby(['pid'])['{cols}'].transform('{func}', {args}) {threshold}\",\n",
    "                               engine='python')\n",
    "            # an attribute (like is_monotonic)\n",
    "            else:\n",
    "                rows = pd.eval(f\"tmpdf.groupby(['pid'])['{cols}'].transform(lambda x: x.{funcexpr})\", engine='python')\n",
    "\n",
    "            info.single_rows[codes] = rows\n",
    "\n",
    "    # if it is a simple quantiative conditions (oxygen_level>20)\n",
    "    elif re.search(quantity, condition):\n",
    "        codetext = condition\n",
    "        codes = condition.split()[-1]  # code condition always last hmm unnecessary\n",
    "        # check if evaluated before\n",
    "        if codes in info.single_rows:\n",
    "            rows = info.single_rows[codes]\n",
    "        # not evaluated before, so calc\n",
    "        else:\n",
    "            # sum(glucose_level)>10\n",
    "            # if this, then may skip further processing?\n",
    "            # well: 1st sum(glucose)>20 ok makes sense, maybe\n",
    "            # but not: max 5 of sum(glucose)>20 ... well maybe\n",
    "            # first 5 of sum(glucose)>20\n",
    "            # if the modifiers does not make sense, the sum might be in the\n",
    "            # list of other modifiers i.e. first 5, 3rd etc and not a\n",
    "            # pre-modifier when finding rows (which allows skipping)\n",
    "\n",
    "            # complex quantitative expression: sum(glucose_level)>10\n",
    "            # better, more flexible ...: glucose.sum()>10 ... can make any function work, and can pass arguments\n",
    "\n",
    "            if 'sum(' in codes:  # can use ddd.cumsum() now, keep this to double check\n",
    "                col, operator = codes.split(')')\n",
    "                col = col.replace('sum(', '').strip(')')\n",
    "                eval_text = f\"df.groupby(df.index)['{col}'].cumsum(){operator}\"\n",
    "                rows = pd.eval(eval_text, engine='python').fillna(False)  # is fillna false better than dropna here?\n",
    "            # simple quantitative expression: glucose_level)>10\n",
    "            else:\n",
    "                rows = df.eval(codes).fillna(False)\n",
    "            codecols = codes\n",
    "            info.single_rows[codecols] = rows\n",
    "\n",
    "\n",
    "    # code expression (involving a code, not a quantitative expressions\n",
    "    else:\n",
    "        codetext, incols = condition.split(' in ')\n",
    "        codes = codetext.split()[-1].strip()  # codes always last in a simple string after cutting 'in cols'\n",
    "\n",
    "        if incols.strip() == '':\n",
    "            cols = cols\n",
    "        else:\n",
    "            cols = incols\n",
    "\n",
    "        codecols = codes + ' in ' + cols + ' row ' + row_selection  # cannot use just codes to store rows since same code may be in different columns, so need to include col in name when storing\n",
    "\n",
    "        # If conditions is about events in general, create an events column\n",
    "        if (' event ' in codes) or (' events ' in codes):\n",
    "            rows = pd.Series(True, index=df.index).fillna(False)\n",
    "            codecols = ' event '\n",
    "        # not a quantitative condition or an event conditions, so it is a code condition\n",
    "        else:\n",
    "            if codecols in info.rows:\n",
    "                rows = info.rows[codecols]\n",
    "            else:\n",
    "                # cols = expand_cols(df=df, cols=cols)\n",
    "                # expanded_codes = expand_codes(df=df, codes=codes, cols=cols, sep=sep)\n",
    "                # allcodes=_get_allcodes(expanded_codes)\n",
    "                # rows = get_rows(df=df, codes=allcodes, cols=cols, sep=sep, fix=False)\n",
    "                rows = use_expression(df=df, expr=codes + ' in:' + cols, sep=sep)\n",
    "\n",
    "                info.rows[codecols] = rows\n",
    "\n",
    "    # is there a prefix to the conditions? if not, isolated condition, just return rows\n",
    "    # if not, start preparing for calculating conditions with qualifiers\n",
    "    # todo: quite messy! refactor: one function to evluate the code/expression itself, another to evalute the qualifier?\n",
    "    if ' ' not in codetext.strip():\n",
    "        # remember answer\n",
    "        info.single_rows[codecols] = rows\n",
    "        info.rows[codecols] = rows\n",
    "\n",
    "        if out == 'pid':\n",
    "            endrows = rows.groupby(level=0).any()\n",
    "            info.single_pid[codecols] = endrows\n",
    "            info.pid[codecols] = endrows\n",
    "        else:\n",
    "            endrows = rows\n",
    "        return endrows\n",
    "\n",
    "    # calculate and remember cumsum per person\n",
    "    # use previous calculation if exist\n",
    "    if codes in info.cumsum:\n",
    "        rowscum = info.cumsum[codes]\n",
    "    else:\n",
    "        rowscum = rows.groupby(level=0).cumsum()\n",
    "        info.cumsum[codecols] = rowscum\n",
    "\n",
    "    ## if not a simple existence condition, it must be one of the conditions below\n",
    "\n",
    "    # positional condition:  5th of 4a, 3rd to 8th of 4A, (3rd, 4th, 5th) of 4A\n",
    "    # also allows: 2nd last (or even -5th last)\n",
    "    if re.match(ordinal, codetext):\n",
    "        pos_str = condition.split('of ')[0].strip().strip('(').strip(')')\n",
    "        # pos_re = ordinal.replace(' ', '[ )]|') # last condition may have ) i.e. 25th)\n",
    "        pos_re = ordinal.replace(' ', '')  # last condition may have ) i.e. 25th)\n",
    "\n",
    "        pos_nums = re.findall(pos_re, pos_str)\n",
    "        pos_nums = tuple([int(pos[0]) for pos in pos_nums])\n",
    "\n",
    "        # if the conditions includes last, need reversed cumsum\n",
    "        if ' last ' in pos_str or '-' in pos_str:\n",
    "            n_max = rowscum.groupby(level=0).max().add(1)\n",
    "            # reversed event number (by id)\n",
    "            lastrowscum = (rowscum - n_max).abs()\n",
    "            last_flag = 1\n",
    "        else:\n",
    "            last_flag = 0\n",
    "\n",
    "        # single position: 5th of 4A\n",
    "        if len(pos_nums) == 1:\n",
    "            if last_flag:\n",
    "                select = (lastrowscum == pos_nums)\n",
    "            else:\n",
    "                select = (rowscum == pos_nums)\n",
    "\n",
    "        # from-to positions: 3rd to 8th of 4A, 1st to -3rd\n",
    "        elif ' to ' in pos_str:\n",
    "            lower, upper = pos_nums\n",
    "            if lower > 0:\n",
    "                aboverows = (rowscum >= lower)\n",
    "            else:\n",
    "                aboverows = (lastrowscum >= abs(lower))\n",
    "\n",
    "            if upper > 0:\n",
    "                belowrows = (rowscum <= upper)\n",
    "            else:\n",
    "                belowrows = (lastrowscum <= abs(upper))\n",
    "\n",
    "            select = (aboverows & belowrows)\n",
    "\n",
    "        # list of positions (3rd, 5th, 7th)\n",
    "        elif pos_str.strip().startswith('('):\n",
    "            pos_num = [num for num in pos_num if num > 0]\n",
    "            neg_num = [num for num in pos_num if num < 0]\n",
    "\n",
    "            if pos_num:\n",
    "                pos_select = rowscum.isin(pos_nums)\n",
    "            if neg_num:\n",
    "                neg_select = rowscum.isin(pos_nums)\n",
    "            select = (pos_select | neg_select)\n",
    "\n",
    "\n",
    "    #  freq condition: min 5 of 4A\n",
    "    elif any(word in codetext for word in freq):\n",
    "        word, num, _, codes = codetext.split()\n",
    "        num = int(num)\n",
    "\n",
    "        if 'min' in word:\n",
    "            select = (rowscum >= num)\n",
    "        elif 'max' in word:  # doublecheck!\n",
    "            n_max = rowscum.max(level=0)\n",
    "            select = (n_max <= num)\n",
    "        elif 'exactly' in word:\n",
    "            select = (rowscum == num)\n",
    "\n",
    "\n",
    "    # first, last range conditions: first 5 of 4A\n",
    "    elif any(word.strip() in condition for word in first_last_between):  # regex is better\n",
    "        word, num, _, codes = codetext.split()\n",
    "        if '%' not in num:\n",
    "            num = int(num)\n",
    "            if 'first' in word:\n",
    "                select = (rowscum <= num)\n",
    "            if 'last' in word:\n",
    "                select = (rowscum >= num)\n",
    "\n",
    "\n",
    "    # if pct condition: first 10% of 4A\n",
    "    elif '%' in codetext:\n",
    "        n_max = rowscum.groupby(level=0).max()\n",
    "        pct = float(num.split(r'%')[0]) / 100\n",
    "        pid_num = n_max * pct\n",
    "\n",
    "        # first 1% of two observations includes 1st obs\n",
    "        pid_num[pid_num < 1] = 1\n",
    "\n",
    "        if word == 'first':\n",
    "            # hmm, generalproblem: drop if pid is missing ...\n",
    "            select = (rowscum < pid_num)\n",
    "\n",
    "        if word == 'last':\n",
    "            select = (rowscum > pid_num)\n",
    "\n",
    "    # percentile condition\n",
    "    elif ' percentile ' in codetext:\n",
    "        event_num = rows.groupby(level=0).cumcount()\n",
    "        n_count = rowscum.groupby(level=0).size()\n",
    "\n",
    "        num = float(num.split(r'%')[0]) / 100\n",
    "\n",
    "        pid_num = n_count * num\n",
    "\n",
    "        if word == 'first':\n",
    "            rows = (pid_num < event_num)\n",
    "\n",
    "        if word == 'last':\n",
    "            rows = (pid_num > event_num)\n",
    "\n",
    "    # so far, have marked interval of events for expressions with qualifications\n",
    "    # (existence conditions are not intervals). example: First 5 of 4A, markes\n",
    "    # all events in the interval between the 1st and 5th of 4A\n",
    "    # if we only want to pick the 4A events in this intereval, we and it with\n",
    "    # the boolena for 4A existence (row). But sometimes we want to keep and use\n",
    "    # the interval. For instance when the qualifiers are used in before/after\n",
    "    # statements if the evaluated expression should be returned as 'exact row',\n",
    "    # 'interval row' or pid existence\n",
    "\n",
    "    # store and return results\n",
    "    if out == 'pid':\n",
    "        endrows = (rows & select)\n",
    "        endrows = endrows.any(level=0)\n",
    "        info.single_pid[original_condition] = endrows\n",
    "        info.single_rows[original_condition] = rows\n",
    "    elif out == 'interval':\n",
    "        endrows = select\n",
    "        info.interval[original_condition] = endrows\n",
    "    elif out == 'rows':\n",
    "        endrows = (rows & select)\n",
    "        info.single_rows[original_condition] = endrows\n",
    "\n",
    "    return endrows\n",
    "\n",
    "\n",
    "  \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8lHw_7wgXaTR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3kN7yEOqjm3V"
   },
   "source": [
    "# get inpatient data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fUwhTeAnzD6q"
   },
   "source": [
    "To test the functions and to calculate the Charslon index we need some data. Here we will use data on hospital visits from Medicare: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3N_2p7tLShTi"
   },
   "outputs": [],
   "source": [
    "# Use pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q_jPK3K_0Vzu"
   },
   "outputs": [],
   "source": [
    "# Read synthetic medicare sample data on inpatient hospital stays\n",
    "path = 'https://www.cms.gov/Research-Statistics-Data-and-Systems/Downloadable-Public-Use-Files/SynPUFs/Downloads/'\n",
    "inpatient_file = 'DE1_0_2008_to_2010_Inpatient_Claims_Sample_1.zip'\n",
    "\n",
    "inpatient = pd.read_csv(path+inpatient_file)\n",
    "\n",
    "inpatient.columns = inpatient.columns.str.lower()\n",
    "# easier to use a column called 'pid' than 'desynpuf_id'\n",
    "inpatient['pid']=inpatient['desynpuf_id']\n",
    "\n",
    "#set index to the personal id, but also keep id as a column\n",
    "inpatient = inpatient.set_index('pid', drop=False)\n",
    "inpatient.index.name='pid_index'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GY1LiGNUShT8"
   },
   "outputs": [],
   "source": [
    "# Have a look\n",
    "inpatient.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxQSMPBZMYXe"
   },
   "outputs": [],
   "source": [
    "# make a list of columns with information about diagnostic codes\n",
    "icd_cols = list(inpatient.columns[inpatient.columns.str.startswith('icd9_dgns_cd')])\n",
    "icd_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c23WbohBbO4R"
   },
   "source": [
    "Make a list of all unique ICD9 codes that exist, a all_codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y2ObFcg_tlMV"
   },
   "outputs": [],
   "source": [
    "# Codes to calculate CCI using ICD-9 (CM, US, Enhanced)\n",
    "# Source: http://mchp-appserv.cpe.umanitoba.ca/concept/Charlson%20Comorbidities%20-%20Coding%20Algorithms%20for%20ICD-9-CM%20and%20ICD-10.pdf\n",
    "\n",
    "infarction = '''\n",
    "      410* \n",
    "      412*\n",
    "      '''\n",
    "\n",
    "heart_failure = '''\n",
    "        390.91 \n",
    "        402.21 402.11 402.91 \n",
    "        404.01 404.03 404.11 404.13 404.91 404.93 \n",
    "        425.4-425.9 \n",
    "        428*\n",
    "        '''\n",
    "\n",
    "peripheral_vascular = '''\n",
    "        093.0\n",
    "        437.3\n",
    "        440*\n",
    "        441*\n",
    "        443.1-443.9\n",
    "        447.1\n",
    "        557.1 557.9\n",
    "        V43.4\n",
    "        '''\n",
    "\n",
    "cerebrovascular = '''\n",
    "        362.34\n",
    "        430*-438*\n",
    "        '''\n",
    "dementia = '''\n",
    "        290*\n",
    "        294.1\n",
    "        331.2\n",
    "        '''\n",
    "\n",
    "pulmonary ='''\n",
    "      416.8 416.9\n",
    "      490*-505* \n",
    "      506.4\n",
    "      508.1 508.8\n",
    "      '''\n",
    "rheumatic = '''\n",
    "      446.5\n",
    "      710.0-710.4\n",
    "      714.0-714.2 714.8\n",
    "      725*\n",
    "      '''\n",
    "\n",
    "peptic_ulcer = '531*-534*'\n",
    "\n",
    "liver_mild ='''\n",
    "      070.22\n",
    "      070.23\n",
    "      070.32\n",
    "      070.33\n",
    "      070.44\n",
    "      070.54\n",
    "      070.6\n",
    "      070.9\n",
    "      570.*\n",
    "      571.*\n",
    "      573.3 573.4 573.8 573.9\n",
    "      V42.7\n",
    "      '''\n",
    "# Interesting, diabetes seems to be 5 digits long in the data, but not the specified codes\n",
    "diabetes_without_complication = '250.0*-250.3* 250.8* 250.9*'\n",
    "\n",
    "diabetes_with_complication = '250.4*-250.7*'\n",
    "\n",
    "plegia = '''\n",
    "    334.1\n",
    "    342.*\n",
    "    343.*\n",
    "    344.0-344.6\n",
    "    344.9\n",
    "    '''\n",
    "\n",
    "renal = '''\n",
    "    403.01 403.11,403.91 \n",
    "    404.02 404.03 404.12 404.13 404.92 404.93\n",
    "    582.*  \n",
    "    583.0-583.7\n",
    "    585*\n",
    "    586*\n",
    "    588.0\n",
    "    V42.0\n",
    "    V45.1\n",
    "    V56*\n",
    "    '''\n",
    "\n",
    "malignancy = '''\n",
    "    140*-172*\n",
    "    174.0-195.8\n",
    "    200*-208*\n",
    "    238.6\n",
    "    '''\n",
    "\n",
    "liver_not_mild = '''\n",
    "    456.0-456.2\n",
    "    572.2-572.8\n",
    "    '''\n",
    "\n",
    "tumor = '196*-199*'\n",
    "\n",
    "hiv = '042*-044*'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lbo8b7wixGH7"
   },
   "source": [
    "Put all the strings that describe the codes for the comorbitities in a single datastructure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x-kLY3dNzfRZ"
   },
   "outputs": [],
   "source": [
    "icd9 = unique(df=inpatient, cols = icd_cols, all_str=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mslB-ZEuxjnm"
   },
   "outputs": [],
   "source": [
    "# A dictionary with names of cormobitities and the associated medical codes\n",
    "\n",
    "code_string = { 'infarction' : infarction, \n",
    "               'heart_failure' : heart_failure, \n",
    "               'peripheral_vascular' : peripheral_vascular, \n",
    "               'cerebrovascular' : cerebrovascular, \n",
    "               'dementia' : dementia, \n",
    "               'pulmonary' : pulmonary, \n",
    "               'rheumatic' : rheumatic, \n",
    "               'peptic_ulcer' : peptic_ulcer, \n",
    "               'liver_mild' : liver_mild, \n",
    "               'diabetes_without_complication' : diabetes_without_complication, \n",
    "               'diabetes_with_complication' : diabetes_with_complication, \n",
    "               'plegia' : plegia, \n",
    "               'renal' : renal, \n",
    "               'malignancy' : malignancy, \n",
    "               'liver_not_mild' : liver_not_mild, \n",
    "               'tumor' : tumor, \n",
    "               'hiv' : hiv}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ctiAl4mHbve-"
   },
   "source": [
    "Having created a all_codes, we can use the functions we have created to expand the description for all the different comorbidities to include all the specific codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l_YMP5Ukbwrv"
   },
   "outputs": [],
   "source": [
    "codes = {disease : expand_code(codes.split(), \n",
    "                               all_codes=icd9,\n",
    "                               drop_dot=True,\n",
    "                               drop_leading_zero=True) \n",
    "        for disease, codes in code_string.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mqLowQI6z9U-"
   },
   "source": [
    "And we can check if it really expanded the codes, for instance by examining the codes for mild liver disease:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "POf4RSz0u20L"
   },
   "outputs": [],
   "source": [
    "codes['liver_mild']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YXrRqq6xrkHP"
   },
   "source": [
    "In order to do the calculations, we need the weights associated with each comorbidity. These weights are related to the predictive power of the comorbididy for the probability of dying in a given time period. There are a few different standards, but with relatively minor varitions. Here we use the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7EKmvFTdx8qT"
   },
   "outputs": [],
   "source": [
    "charlson_points = { 'infarction': 1, \n",
    "                   'heart_failure': 1, \n",
    "                   'peripheral_vascular': 1, \n",
    "                   'cerebrovascular': 1, \n",
    "                   'dementia': 1, \n",
    "                   'pulmonary': 1, \n",
    "                   'rheumatic': 1, \n",
    "                   'peptic_ulcer': 1, \n",
    "                   'liver_mild': 1, \n",
    "                   'diabetes_without_complication': 1, \n",
    "                   'diabetes_with_complication': 2, \n",
    "                   'plegia': 2, \n",
    "                   'renal': 2, \n",
    "                   'malignancy': 2, \n",
    "                   'liver_not_mild': 3, \n",
    "                   'tumor': 6, \n",
    "                   'hiv': 6}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wghaUi_Fj2SS"
   },
   "source": [
    "We also need the function that takes a set of codes and identifies the rows and persons who have the codes (a function we developed in a previous notebook):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted query_language.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "query language v1",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
